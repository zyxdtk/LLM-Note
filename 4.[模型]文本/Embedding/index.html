<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../img/favicon.ico" />
    <title>Embedding - 大模型笔记</title>
    <link rel="stylesheet" href="../../css/theme.css" />
    <link rel="stylesheet" href="../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Embedding";
        var mkdocs_page_input_path = "4.[\u6a21\u578b]\u6587\u672c/Embedding.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../.." class="icon icon-home"> 大模型笔记
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../..">Home</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">0.inbox</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../0.inbox/%5BRead%5D2025-04/">[Read]2025 04</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../0.inbox/alg-interview-faq/">Alg interview faq</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">1.[基建]数据</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../1.%5B%E5%9F%BA%E5%BB%BA%5D%E6%95%B0%E6%8D%AE/data/">Data</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">3.[基建]效率</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../3.%5B%E5%9F%BA%E5%BB%BA%5D%E6%95%88%E7%8E%87/Inference/">Inference</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../3.%5B%E5%9F%BA%E5%BB%BA%5D%E6%95%88%E7%8E%87/train/">Train</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">4.[模型]文本</span></p>
              <ul class="current">
                  <li class="toctree-l1 current"><a class="reference internal current" href="#">Embedding</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#_1">学习资料</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#benchmark">benchmark</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#_2">论文</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#transformer">基于Transformer架构</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#_3">训练技术</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#1">1. 目标函数</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#2">2. 数据增强</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#3">3. 训练技巧</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#_4">评估指标</a>
    </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../PostTraining/">PostTraining</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../PreTraining/">PreTraining</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">5.[模型]多模态</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../5.%5B%E6%A8%A1%E5%9E%8B%5D%E5%A4%9A%E6%A8%A1%E6%80%81/MultiModalEmbedding/">MultiModalEmbedding</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../5.%5B%E6%A8%A1%E5%9E%8B%5D%E5%A4%9A%E6%A8%A1%E6%80%81/T2V/">T2V</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../5.%5B%E6%A8%A1%E5%9E%8B%5D%E5%A4%9A%E6%A8%A1%E6%80%81/VLA/">VLA</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../5.%5B%E6%A8%A1%E5%9E%8B%5D%E5%A4%9A%E6%A8%A1%E6%80%81/VLM/">VLM</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">6.[模型]评测</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../6.%5B%E6%A8%A1%E5%9E%8B%5D%E8%AF%84%E6%B5%8B/Benchmark/">Benchmark</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">7.[应用]产品</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../7.%5B%E5%BA%94%E7%94%A8%5D%E4%BA%A7%E5%93%81/Agent/">Agent</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../7.%5B%E5%BA%94%E7%94%A8%5D%E4%BA%A7%E5%93%81/Product/">Product</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../7.%5B%E5%BA%94%E7%94%A8%5D%E4%BA%A7%E5%93%81/VibeCoding/">VibeCoding</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../..">大模型笔记</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../.." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">4.[模型]文本</li>
      <li class="breadcrumb-item active">Embedding</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h2 id="embedding">文本Embedding技术<a class="headerlink" href="#embedding" title="Permanent link">#</a></h2>
<h3 id="_1">学习资料<a class="headerlink" href="#_1" title="Permanent link">#</a></h3>
<ul>
<li><a href="https://www.sbert.net/">sbert</a> <ul>
<li><a href="https://discuss.huggingface.co/t/train-the-best-sentence-embedding-model-ever-with-1b-training-pairs/7354">用1B个对比对训练最好的句向量模型</a> 源于这样的认知：更多更多样的数据+更大BatchSize可以训练出更好的Embedding模型。</li>
<li><a href="https://github.com/UKPLab/sentence-transformers">sentence-transformers</a></li>
</ul>
</li>
</ul>
<h3 id="benchmark">benchmark<a class="headerlink" href="#benchmark" title="Permanent link">#</a></h3>
<ul>
<li><a href="https://github.com/embeddings-benchmark/mteb">MTEB评估基准</a><ul>
<li><a href="https://huggingface.co/spaces/mteb/leaderboard">mteb/leaderboard</a></li>
</ul>
</li>
</ul>
<h3 id="_2">论文<a class="headerlink" href="#_2" title="Permanent link">#</a></h3>
<h4 id="transformer">基于Transformer架构<a class="headerlink" href="#transformer" title="Permanent link">#</a></h4>
<ul>
<li>[2025.03] <a href="https://www.arxiv.org/abs/2503.07891">Gemini Embedding: Generalizable Embeddings from Gemini</a> google sota效果。难负例、合成数据蒸馏大模型、用LLM初始化。引入task prompts and a pre-finetuning stage进一步提高效果。用Model Soup来融合多个checkpoint的效果。mean polling 然后过一个linear到目标维度。nce。</li>
<li>[2024.09] <a href="https://arxiv.org/pdf/2309.07597">C-Pack: Packed Resources For General Chinese Embeddings</a> 智源开源。分三个阶段：预训练、对比对学习、任务精调。预训练使用retroMAE，用in-batch负采样，batchsize 19200，任务精调用ann挑选难负样本。<ul>
<li><a href="https://github.com/FlagOpen/FlagEmbedding">FlagEmbedding</a></li>
<li><a href="https://huggingface.co/BAAI/bge-large-zh-v1.5">bge-large-zh-v1.5</a></li>
<li><a href="https://huggingface.co/BAAI/bge-reranker-large">bge-reranker-large</a></li>
<li>[2022.10] <a href="https://arxiv.org/pdf/2205.12035">RetroMAE: Pre-Training Retrieval-oriented Language Models Via Masked Auto-Encoder</a></li>
</ul>
</li>
<li>[2023.08] <a href="https://arxiv.org/abs/2308.03281">Towards General Text Embeddings with Multi-stage Contrastive Learning</a> 阿里开源。infoNCE。mean polling，两阶段：大batchsize的in-batch训练。难负样本训练。</li>
<li><a href="https://huggingface.co/thenlper/gte-large-zh">gte-large-zh</a></li>
<li>[2022.08] <a href="SGPT: GPT Sentence Embeddings for Semantic Search">https://arxiv.org/pdf/2202.08904v5</a> 清华，对比了 cross-encoder vs bi-encoder，使用位置加权的mean polling，只是fine-tunning了bias</li>
<li>[2022.01] <a href="https://arxiv.org/pdf/2201.10005">Text and Code Embeddings by Contrastive Pre-Training</a> openai 1. 预训练模型作为初始化模型 2. 大batch的对比学习logit，相似度+交叉熵+in-batch负采样 3. Fine-tuning (非必须)</li>
<li>[2021.04] <a href="https://arxiv.org/abs/2104.08821">SimCSE: Simple Contrastive Learning of Sentence Embeddings</a><ul>
<li><a href="https://github.com/princeton-nlp/SimCSE#model-list">github:SimCSE</a></li>
</ul>
</li>
<li>[2020.09] <a href="https://arxiv.org/pdf/2004.04906">Dense Passage Retrieval for Open-Domain Question Answering</a> meta<ul>
<li>https://huggingface.co/docs/transformers/model_doc/dpr#overview</li>
<li><a href="https://github.com/facebookresearch/DPR">github:DPR</a></li>
</ul>
</li>
</ul>
<h3 id="_3">训练技术<a class="headerlink" href="#_3" title="Permanent link">#</a></h3>
<h4 id="1">1. 目标函数<a class="headerlink" href="#1" title="Permanent link">#</a></h4>
<ul>
<li>对比损失(Contrastive Loss)</li>
<li>三重损失(Triplet Loss)</li>
<li>余弦相似度损失</li>
</ul>
<h4 id="2">2. 数据增强<a class="headerlink" href="#2" title="Permanent link">#</a></h4>
<ul>
<li>回译(Back Translation)</li>
<li>词语删除/替换</li>
<li>对抗样本生成</li>
<li>难例挖掘(Hard Negative Mining)</li>
<li>合成数据<ul>
<li>[2024.5] <a href="https://arxiv.org/abs/2401.00368">Improving Text Embeddings with Large Language Models</a> 用LLM合成93种语言的finetune数据。</li>
<li>[2024.03] <a href="https://arxiv.org/abs/2403.20327">Gecko: Versatile Text Embeddings Distilled from Large Language Models</a> 从LLM蒸馏知识。用LLM生成QA对，然后对每一个query精挑A，标注正例和难负例。</li>
<li>[2022.09] <a href="https://arxiv.org/abs/2209.11755">Promptagator: Few-shot Dense Retrieval From 8 Examples</a> 用few-shot的prompt来生成query</li>
</ul>
</li>
</ul>
<h4 id="3">3. 训练技巧<a class="headerlink" href="#3" title="Permanent link">#</a></h4>
<ul>
<li>层归一化策略</li>
<li>温度系数调节</li>
<li>输出维度<ul>
<li>[2022.04] <a href="https://arxiv.org/abs/2205.13147">Matryoshka Representation Learning</a> 用一个Embedding上构建不同的loss，每个loss使用不同数量和组合的维度。</li>
</ul>
</li>
</ul>
<h3 id="_4">评估指标<a class="headerlink" href="#_4" title="Permanent link">#</a></h3>
<table>
<thead>
<tr>
<th>指标名称</th>
<th>说明</th>
<th>典型数据集</th>
</tr>
</thead>
<tbody>
<tr>
<td>Spearman相关性</td>
<td>排名相关性</td>
<td>STS-B</td>
</tr>
<tr>
<td>Recall@K</td>
<td>检索召回率</td>
<td>MS-MARCO</td>
</tr>
<tr>
<td>聚类纯度</td>
<td>聚类效果评估</td>
<td>AG News</td>
</tr>
</tbody>
</table>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../../3.%5B%E5%9F%BA%E5%BB%BA%5D%E6%95%88%E7%8E%87/train/" class="btn btn-neutral float-left" title="Train"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../PostTraining/" class="btn btn-neutral float-right" title="PostTraining">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../../3.%5B%E5%9F%BA%E5%BB%BA%5D%E6%95%88%E7%8E%87/train/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../PostTraining/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../..";</script>
    <script src="../../js/theme_extra.js"></script>
    <script src="../../js/theme.js"></script>
      <script src="../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
