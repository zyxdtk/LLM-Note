{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"\u5927\u6a21\u578b\u5b66\u4e60\u7b14\u8bb0\u548c\u9762\u8bd5\u9898 # \u7f51\u5740: zyxdtk.github.io/LLM-Note","title":"Home"},{"location":"#_1","text":"\u7f51\u5740: zyxdtk.github.io/LLM-Note","title":"\u5927\u6a21\u578b\u5b66\u4e60\u7b14\u8bb0\u548c\u9762\u8bd5\u9898"},{"location":"0.inbox/%5BRead%5D2025-04/","text":"2025-04 # \u6587\u672c # [2025.04] OTC: Optimal Tool Calls via Reinforcement Learning [2025.04] CLIMB: CLustering-based Iterative Data Mixture Bootstrapping for Language Model Pre-training [2025.04] VAPO: Efficient and Reliable Reinforcement Learning for Advanced Reasoning Tasks [2025.03] DAPO: An Open-Source LLM Reinforcement Learning System at Scale Dialogue Natural Language Inference Generative Recommendation: Towards Next-generation Recommender Paradigm Observational Scaling Laws and the Predictability of Language Model Performance [todo] LLM Research Papers: The 2024 List \u7cfb\u7edf\u8bba\u8ff0\uff1a\u6784\u5efa\u9ad8\u6027\u80fd Prompt \u4e4b\u8def\u2014\u2014\u7ed3\u6784\u5316 Prompt https://www.blog.chai-research.com/post/chai-gpt-rlhf-part-i-reward-modelling chai\u7684rl https://github.com/volcengine/verl \u5f3a\u5316\u5b66\u4e60\u6846\u67b6 \u3010\u8bba\u6587\u89e3\u8bfb\u3011MTP\uff1a\u8ba9LLM\u4e00\u6b21\u6027\u9884\u6d4b\u591a\u4e2atoken \u4e00\u4e2aemb\u51fa\u591a\u4e2ahead \u3010\u8bba\u6587\u89e3\u8bfb\u3011SPCT\uff1aDeepSeek \u7684\u300c\u901a\u7528\u300d\u5956\u52b1\u6a21\u578b\u8bad\u7ec3\u65b9\u6cd5 \u8bed\u97f3 # \u8bed\u97f3\u5927\u6a21\u578b\u6982\u8ff0\uff08\u6301\u7eed\u66f4\u65b0\u4e2d2025.03\uff09 \u603b\u7ed3\u5f97\u5f88\u597d\u3002\u9700\u8981\u4e86\u89e3hifi-gan\u3001RVQ [2025.02] Recent Advances in Speech Language Models: A Survey \u8fd8\u6ca1\u770b\uff0c\u6536\u85cf Baichuan-Audio\uff1a\u7aef\u5230\u7aef\u97f3\u9891\u5927\u6a21\u578b\uff0c\u5b9e\u65f6\u53cc\u8bed\u5bf9\u8bdd+\u8bed\u97f3\u751f\u6210 \u56fe\u50cf # MiniMax-AI/One-RL-to-See-Them-All ViT\uff08Vision Transformer\uff09\u89e3\u6790 https://paperswithcode.com/sota/image-classification-on-imagenet \u56fe\u50cf\u5206\u7c7b\u7684benchmark \u5e94\u7528 # Agent \u8981\u88ab\u5403\u8fdb\u5927\u6a21\u578b\u4e86 \u540c\u65f6\u505a\u5e95\u6a21\u548cRL\u66f4\u80fd\u505a\u597dagent GenAI\u7f51\u9875\u6570\u636e2024\u5e74\u5ea6\u62a5\u544a https://pippit.capcut.com/ https://ai-2027.com/ \u8c37\u6b4cAgent2Agent (A2A) \u534f\u8bae\u6280\u672f\u7ec6\u8282\u5206\u6790\uff0c\u5305\u62ec\u5176\u4e0e MCP \u5173\u7cfb \u5927\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\u2014\u2014MCP\u8be6\u89e3 \u9762\u7ecf # \u624b\u6495\u5927\u6a21\u578b\u9762\u8bd5\u7cfb\u5217 \u3010\u9762\u7ecf\u3011\u9762\u4e86\u963f\u91cc\u6dd8\u5929\u5927\u6a21\u578b\u7b97\u6cd5\u5c97\uff0c\u6574\u4f53\u6c1b\u56f4\u6bd4\u8f83\u8f7b\u677e \u540d\u4eba\u8bbf\u8c08 # \u95eb\u4fca\u6770\u5bf9\u8bdd\u9ec4\u660e\u660e\uff1aAGI\uff0c\u53ea\u6709\u4e00\u6761\u6700\u96be\u4f46\u552f\u4e00\u7684\u9053\u8def \u6df1\u5ea6\uff5cMeta\u9996\u5e2d\u79d1\u5b66\u5bb6LeCun\uff1aMeta\u6b63\u7814\u7a76\u65b0\u4e00\u4ee3Agentic\u7cfb\u7edf\uff0c\u80fd\u591f\u7406\u89e3\u7269\u7406\u4e16\u754c\u5e76\u89c4\u5212\u884c\u52a8\u5b9e\u73b0\u76ee\u6807 [todo] Pre-Training GPT-4.5 \u751f\u4ea7\u529b\u5de5\u5177\u5927\u6bd4\u62fc\uff01\u80fd\u6253\u7684\u6d77\u87baAI\u4e5f\u8be5\u51fa\u6765\u597d\u597d\u4eae\u76f8\u4e86\uff01","title":"[Read]2025 04"},{"location":"0.inbox/%5BRead%5D2025-04/#2025-04","text":"","title":"2025-04"},{"location":"0.inbox/%5BRead%5D2025-04/#_1","text":"[2025.04] OTC: Optimal Tool Calls via Reinforcement Learning [2025.04] CLIMB: CLustering-based Iterative Data Mixture Bootstrapping for Language Model Pre-training [2025.04] VAPO: Efficient and Reliable Reinforcement Learning for Advanced Reasoning Tasks [2025.03] DAPO: An Open-Source LLM Reinforcement Learning System at Scale Dialogue Natural Language Inference Generative Recommendation: Towards Next-generation Recommender Paradigm Observational Scaling Laws and the Predictability of Language Model Performance [todo] LLM Research Papers: The 2024 List \u7cfb\u7edf\u8bba\u8ff0\uff1a\u6784\u5efa\u9ad8\u6027\u80fd Prompt \u4e4b\u8def\u2014\u2014\u7ed3\u6784\u5316 Prompt https://www.blog.chai-research.com/post/chai-gpt-rlhf-part-i-reward-modelling chai\u7684rl https://github.com/volcengine/verl \u5f3a\u5316\u5b66\u4e60\u6846\u67b6 \u3010\u8bba\u6587\u89e3\u8bfb\u3011MTP\uff1a\u8ba9LLM\u4e00\u6b21\u6027\u9884\u6d4b\u591a\u4e2atoken \u4e00\u4e2aemb\u51fa\u591a\u4e2ahead \u3010\u8bba\u6587\u89e3\u8bfb\u3011SPCT\uff1aDeepSeek \u7684\u300c\u901a\u7528\u300d\u5956\u52b1\u6a21\u578b\u8bad\u7ec3\u65b9\u6cd5","title":"\u6587\u672c"},{"location":"0.inbox/%5BRead%5D2025-04/#_2","text":"\u8bed\u97f3\u5927\u6a21\u578b\u6982\u8ff0\uff08\u6301\u7eed\u66f4\u65b0\u4e2d2025.03\uff09 \u603b\u7ed3\u5f97\u5f88\u597d\u3002\u9700\u8981\u4e86\u89e3hifi-gan\u3001RVQ [2025.02] Recent Advances in Speech Language Models: A Survey \u8fd8\u6ca1\u770b\uff0c\u6536\u85cf Baichuan-Audio\uff1a\u7aef\u5230\u7aef\u97f3\u9891\u5927\u6a21\u578b\uff0c\u5b9e\u65f6\u53cc\u8bed\u5bf9\u8bdd+\u8bed\u97f3\u751f\u6210","title":"\u8bed\u97f3"},{"location":"0.inbox/%5BRead%5D2025-04/#_3","text":"MiniMax-AI/One-RL-to-See-Them-All ViT\uff08Vision Transformer\uff09\u89e3\u6790 https://paperswithcode.com/sota/image-classification-on-imagenet \u56fe\u50cf\u5206\u7c7b\u7684benchmark","title":"\u56fe\u50cf"},{"location":"0.inbox/%5BRead%5D2025-04/#_4","text":"Agent \u8981\u88ab\u5403\u8fdb\u5927\u6a21\u578b\u4e86 \u540c\u65f6\u505a\u5e95\u6a21\u548cRL\u66f4\u80fd\u505a\u597dagent GenAI\u7f51\u9875\u6570\u636e2024\u5e74\u5ea6\u62a5\u544a https://pippit.capcut.com/ https://ai-2027.com/ \u8c37\u6b4cAgent2Agent (A2A) \u534f\u8bae\u6280\u672f\u7ec6\u8282\u5206\u6790\uff0c\u5305\u62ec\u5176\u4e0e MCP \u5173\u7cfb \u5927\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\u2014\u2014MCP\u8be6\u89e3","title":"\u5e94\u7528"},{"location":"0.inbox/%5BRead%5D2025-04/#_5","text":"\u624b\u6495\u5927\u6a21\u578b\u9762\u8bd5\u7cfb\u5217 \u3010\u9762\u7ecf\u3011\u9762\u4e86\u963f\u91cc\u6dd8\u5929\u5927\u6a21\u578b\u7b97\u6cd5\u5c97\uff0c\u6574\u4f53\u6c1b\u56f4\u6bd4\u8f83\u8f7b\u677e","title":"\u9762\u7ecf"},{"location":"0.inbox/%5BRead%5D2025-04/#_6","text":"\u95eb\u4fca\u6770\u5bf9\u8bdd\u9ec4\u660e\u660e\uff1aAGI\uff0c\u53ea\u6709\u4e00\u6761\u6700\u96be\u4f46\u552f\u4e00\u7684\u9053\u8def \u6df1\u5ea6\uff5cMeta\u9996\u5e2d\u79d1\u5b66\u5bb6LeCun\uff1aMeta\u6b63\u7814\u7a76\u65b0\u4e00\u4ee3Agentic\u7cfb\u7edf\uff0c\u80fd\u591f\u7406\u89e3\u7269\u7406\u4e16\u754c\u5e76\u89c4\u5212\u884c\u52a8\u5b9e\u73b0\u76ee\u6807 [todo] Pre-Training GPT-4.5 \u751f\u4ea7\u529b\u5de5\u5177\u5927\u6bd4\u62fc\uff01\u80fd\u6253\u7684\u6d77\u87baAI\u4e5f\u8be5\u51fa\u6765\u597d\u597d\u4eae\u76f8\u4e86\uff01","title":"\u540d\u4eba\u8bbf\u8c08"},{"location":"0.inbox/alg-interview-faq/","text":"\u7b97\u6cd5\u9762\u8bd5\u95ee\u9898 # \u6280\u672f\u95ee\u9898 # \u6a21\u578b\u7ed3\u6784 # deepseek\u6709\u4ec0\u4e48\u505a\u7684\u4e0d\u597d\u7684\u5730\u65b9\uff1f\u5982\u4f55\u6539\u8fdb\uff1f \u591a\u5c11\u6570\u636e\u91cf\u80fd\u8ba9\u6a21\u578bwork\uff1f \u9884\u8bad\u7ec3 # \u9884\u8bad\u7ec3\u6570\u636e\uff0c\u600e\u4e48\u4fdd\u8bc1\u6570\u636e\u662f\u65b0\u77e5\u8bc6\uff1f \u9884\u8bad\u7ec3\u7528kenlm\u505a\u8fc7\u6ee4\uff0c\u8fd9\u4e2a\u5bf9\u5417\uff1fppl\u9ad8\u7684\u6570\u636e\u4e00\u5b9a\u8981\u4e22\u5f03\uff1f tokenizer\u600e\u4e48\u9009\uff1fBBPE\u4e86\u89e3\u5417\uff1f BPE\u548cwordpiece\u7684\u533a\u522b\uff1f\u5206\u522b\u9002\u5408\u4ec0\u4e48\u4efb\u52a1\uff1f \u540e\u8bad\u7ec3 # \u5728\u5927\u6a21\u578b\u5bf9\u9f50\u4e2d\uff0c\u4e24\u4e2a\u4efb\u52a1\u7684\u6570\u636e\u96c6\u5408\u5e76\u7684\u65f6\u5019\u6307\u6807\u4e0b\u964d\uff0c\u662f\u4ec0\u4e48\u539f\u56e0\uff1f\u600e\u4e48\u89e3\u51b3\uff1f RL\u662f\u600e\u4e48\u8bad\u7ec3\u7684\uff0c\u9047\u5230\u4e86\u4ec0\u4e48\u95ee\u9898\uff1f DPO\u4e3a\u4ec0\u4e48\u4f1a\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u53d8\u957f \u5e94\u7528\u95ee\u9898 # \u5de5\u5177\u7c7b\u5e94\u7528\uff0c\u6bd4\u5982devin\u3001lovable\u662f\u600e\u4e48\u505a\u7684\uff0c\u4f60\u770b\u597d\u4ed6\u4eec\u7684\u524d\u666f\u5417\uff1f deepsearch \u662f\u600e\u4e48\u5b9e\u73b0\u7684\uff1f \u5408\u6210\u6570\u636e # \u5408\u6210\u6570\u636e\u505a\u5f97\u6700\u597d\u7684\u662f\u54ea\u5bb6\u516c\u53f8\uff1f \u63a8\u8350\u548cLLM\u4e4b\u95f4\u6709\u4ec0\u4e48\u53ef\u4ee5\u76f8\u4e92\u501f\u9274\u7684\u5730\u65b9\uff1f # HR\u9762 # \u4f60\u662f\u4e00\u4f4d\u7b97\u6cd5\u5de5\u7a0b\u5e08\uff0c\u4f60\u600e\u4e48\u8bc4\u4ef7\u4f60\u81ea\u5df1\uff1f #","title":"Alg interview faq"},{"location":"0.inbox/alg-interview-faq/#_1","text":"","title":"\u7b97\u6cd5\u9762\u8bd5\u95ee\u9898"},{"location":"0.inbox/alg-interview-faq/#_2","text":"","title":"\u6280\u672f\u95ee\u9898"},{"location":"0.inbox/alg-interview-faq/#_3","text":"deepseek\u6709\u4ec0\u4e48\u505a\u7684\u4e0d\u597d\u7684\u5730\u65b9\uff1f\u5982\u4f55\u6539\u8fdb\uff1f \u591a\u5c11\u6570\u636e\u91cf\u80fd\u8ba9\u6a21\u578bwork\uff1f","title":"\u6a21\u578b\u7ed3\u6784"},{"location":"0.inbox/alg-interview-faq/#_4","text":"\u9884\u8bad\u7ec3\u6570\u636e\uff0c\u600e\u4e48\u4fdd\u8bc1\u6570\u636e\u662f\u65b0\u77e5\u8bc6\uff1f \u9884\u8bad\u7ec3\u7528kenlm\u505a\u8fc7\u6ee4\uff0c\u8fd9\u4e2a\u5bf9\u5417\uff1fppl\u9ad8\u7684\u6570\u636e\u4e00\u5b9a\u8981\u4e22\u5f03\uff1f tokenizer\u600e\u4e48\u9009\uff1fBBPE\u4e86\u89e3\u5417\uff1f BPE\u548cwordpiece\u7684\u533a\u522b\uff1f\u5206\u522b\u9002\u5408\u4ec0\u4e48\u4efb\u52a1\uff1f","title":"\u9884\u8bad\u7ec3"},{"location":"0.inbox/alg-interview-faq/#_5","text":"\u5728\u5927\u6a21\u578b\u5bf9\u9f50\u4e2d\uff0c\u4e24\u4e2a\u4efb\u52a1\u7684\u6570\u636e\u96c6\u5408\u5e76\u7684\u65f6\u5019\u6307\u6807\u4e0b\u964d\uff0c\u662f\u4ec0\u4e48\u539f\u56e0\uff1f\u600e\u4e48\u89e3\u51b3\uff1f RL\u662f\u600e\u4e48\u8bad\u7ec3\u7684\uff0c\u9047\u5230\u4e86\u4ec0\u4e48\u95ee\u9898\uff1f DPO\u4e3a\u4ec0\u4e48\u4f1a\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u53d8\u957f","title":"\u540e\u8bad\u7ec3"},{"location":"0.inbox/alg-interview-faq/#_6","text":"\u5de5\u5177\u7c7b\u5e94\u7528\uff0c\u6bd4\u5982devin\u3001lovable\u662f\u600e\u4e48\u505a\u7684\uff0c\u4f60\u770b\u597d\u4ed6\u4eec\u7684\u524d\u666f\u5417\uff1f deepsearch \u662f\u600e\u4e48\u5b9e\u73b0\u7684\uff1f","title":"\u5e94\u7528\u95ee\u9898"},{"location":"0.inbox/alg-interview-faq/#_7","text":"\u5408\u6210\u6570\u636e\u505a\u5f97\u6700\u597d\u7684\u662f\u54ea\u5bb6\u516c\u53f8\uff1f","title":"\u5408\u6210\u6570\u636e"},{"location":"0.inbox/alg-interview-faq/#llm","text":"","title":"\u63a8\u8350\u548cLLM\u4e4b\u95f4\u6709\u4ec0\u4e48\u53ef\u4ee5\u76f8\u4e92\u501f\u9274\u7684\u5730\u65b9\uff1f"},{"location":"0.inbox/alg-interview-faq/#hr","text":"","title":"HR\u9762"},{"location":"0.inbox/alg-interview-faq/#_8","text":"","title":"\u4f60\u662f\u4e00\u4f4d\u7b97\u6cd5\u5de5\u7a0b\u5e08\uff0c\u4f60\u600e\u4e48\u8bc4\u4ef7\u4f60\u81ea\u5df1\uff1f"},{"location":"1.%5B%E5%9F%BA%E5%BB%BA%5D%E6%95%B0%E6%8D%AE/data/","text":"\u6570\u636e\u6e05\u6d17 # [2024.02] Clustering and Ranking: Diversity-preserved Instruction Selection through Expert-aligned Quality Estimation \u7528rm\u5bf9qa\u5bf9\u6253\u5206\u7136\u540e\u6392\u5e8f\u3002pca\u964d\u7ef4\uff0ckmeans\u805a\u7c7b\u3002 [2023.12] What Makes Good Data for Alignment? A Comprehensive Study of Automatic Data Selection in Instruction Tuning deita\u3002complexity, quality, and diversity\u3002\u7528gpt\u6765\u7ed9\u6307\u4ee4\u548cQA\u5bf9\u6253\u590d\u6742\u5ea6\u548c\u8d28\u91cf\u5206\uff0c\u7528emb_sim\u6765\u8bc4\u4f30\u76f8\u4f3c\u5ea6\u3002 \u8bba\u6587\u89e3\u8bfb\uff1a\u5982\u4f55\u81ea\u52a8\u9009\u62e9SFT\u6570\u636e LLM\u6a21\u578b\u4e4b\u9ad8\u8d28\u91cf\u6570\u636e\u9009\u62e9\u548c\u5fae\u8c03\u65b9\u6cd5 [2023.08] InsTag: Instruction Tagging for Analyzing Supervised Fine-tuning of Large Language Models instag","title":"Data"},{"location":"1.%5B%E5%9F%BA%E5%BB%BA%5D%E6%95%B0%E6%8D%AE/data/#_1","text":"[2024.02] Clustering and Ranking: Diversity-preserved Instruction Selection through Expert-aligned Quality Estimation \u7528rm\u5bf9qa\u5bf9\u6253\u5206\u7136\u540e\u6392\u5e8f\u3002pca\u964d\u7ef4\uff0ckmeans\u805a\u7c7b\u3002 [2023.12] What Makes Good Data for Alignment? A Comprehensive Study of Automatic Data Selection in Instruction Tuning deita\u3002complexity, quality, and diversity\u3002\u7528gpt\u6765\u7ed9\u6307\u4ee4\u548cQA\u5bf9\u6253\u590d\u6742\u5ea6\u548c\u8d28\u91cf\u5206\uff0c\u7528emb_sim\u6765\u8bc4\u4f30\u76f8\u4f3c\u5ea6\u3002 \u8bba\u6587\u89e3\u8bfb\uff1a\u5982\u4f55\u81ea\u52a8\u9009\u62e9SFT\u6570\u636e LLM\u6a21\u578b\u4e4b\u9ad8\u8d28\u91cf\u6570\u636e\u9009\u62e9\u548c\u5fae\u8c03\u65b9\u6cd5 [2023.08] InsTag: Instruction Tagging for Analyzing Supervised Fine-tuning of Large Language Models instag","title":"\u6570\u636e\u6e05\u6d17"},{"location":"3.%5B%E5%9F%BA%E5%BB%BA%5D%E6%95%88%E7%8E%87/Inference/","text":"1. \u5927\u6a21\u578b\u63a8\u7406\u5b66\u4e60\u8d44\u6599 # LLM\u63a8\u7406\u4f18\u5316\u6280\u672f\u8be6\u89e3 \u63a8\u7406\u52a0\u901f\u65b9\u6cd5 github:vLLM \u9ad8\u6027\u80fd\u63a8\u7406\u6846\u67b6 NVIDIA/FasterTransformer \u5206\u6790transformer\u6a21\u578b\u7684\u53c2\u6570\u91cf\u3001\u8ba1\u7b97\u91cf\u3001\u4e2d\u95f4\u6fc0\u6d3b\u3001KV cache 2. \u5927\u6a21\u578b\u63a8\u7406\u4f18\u5316 # \u5927\u6a21\u578b\u63a8\u7406\u5173\u6ce8\uff1a\u5ef6\u8fdf\u3001\u541e\u5410\u548c\u6210\u672c\uff0c\u4f18\u5316\u5206\uff1a\u6539\u6a21\u578b\u53c2\u6570\u3001\u5355\u673a\u4f18\u5316\u3001\u5206\u5e03\u5f0f\u4f18\u5316\u3002 \u6539\u6a21\u578b\u53c2\u6570\u3002 \u91cf\u5316 attention\u7ed3\u6784(mha\u3001mqa\u3001mla\u3001sparse attention\u3001 liner attention) ffn\u7ed3\u6784(moe) \u5176\u4ed6\u7ed3\u6784(silu\u3001rmsnorm) \u968f\u673a\u89e3\u7801\u3002 \u5355\u673a\u4f18\u5316\u3002LLM\u662fio\u7ea6\u675f\u7684\u3002 \u7b97\u5b50\u878d\u5408\u3002qkv\u878d\u5408\uff0cbias\u878d\u5408\u3002 \u9ad8\u6027\u80fd\u7b97\u5b50\u3002flash attention\u3001\u9ad8\u6027\u80fd\u77e9\u9635\u8fd0\u7b97gemm\u3002\u9700\u8981\u6df1\u5165\u5230kernel\u5c42\u9762\u3002 \u5185\u5b58\u7ba1\u7406\u3002continuous batching\u3001paged attention\u3002 \u5206\u5e03\u5f0f\u4f18\u5316\u3002 \u6a21\u578b\u5e76\u884c\u3002tensor\u5e76\u884c\u3001pipeline\u5e76\u884c\u3001\u4e13\u5bb6\u5e76\u884c \u6570\u636e\u5e76\u884c\u3002zero3 \u786c\u4ef6\u7279\u5316\u3002prefill\u548cgenerate\u5206\u79bb\u3002 2.1. \u6539\u6a21\u578b\u53c2\u6570 # 2.1.1. \u91cf\u5316 # [2025.01] Qrazor: Reliable and Effortless 4-bit LLM Quantization by Significant Data Razoring [2023.10] LLM-FP4: 4-Bit Floating-Point Quantized Transformers [2023.09] Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs AutoRound intel/auto-round [2023.06] AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration AWQ [2022.10] GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers GPTQ [2022.08] LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale LLM.int8(): 8-bit\u91cf\u5316\u63a8\u7406 2.1.2. attention\u7ed3\u6784 # FlashMLA 2.1.3. \u5e76\u884c\u89e3\u7801 # [2024.01] EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty \u8bba\u6587\u89e3\u8bfb\u3011EAGLE\uff1a\u5728\u7279\u5f81\u5c42\u8fdb\u884c\u81ea\u56de\u5f52\u7684\u6295\u673a\u91c7\u6837\u6846\u67b6 [2024.01] Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads \u52a0\u591a\u4e2a\u89e3\u7801\u5934\uff0c\u7528topk\u89e3\u7801\u591a\u4e2atoken\uff0c\u7528tree attention\u5224\u5b9a\u662f\u5426\u91c7\u7eb3\u3002 [2023.10] Lookahead: An Inference Acceleration Framework for Large Language Model with Lossless Generation Accuracy \u75282D\u7a97\u53e3\u7ef4\u62a4\u591a\u4e2angram [2022.11] Fast Inference from Transformers via Speculative Decoding \u5c0f\u6a21\u578b\u9884\u4f30\uff0c\u5927\u6a21\u578b\u5224\u5b9a\u662f\u5426\u91c7\u7eb3\u3002\u8ba1\u7b97\u91cf\u4e0d\u53d8\uff0c\u4f46\u662f\u53ef\u4ee5\u5e76\u884c\u5316\u4e86\u3002 2.2. \u5355\u673a\u4f18\u5316 # 2.2.1. attention # [2023.09] Efficient Memory Management for Large Language Model Serving with PagedAttention PagedAttention,\u865a\u62df\u5185\u5b58\u6280\u672f\uff0c\u5206\u9875\u3002\u6bd4\u6734\u7d20batch\u5feb22\u500d\u541e\u5410\uff0c\u6bd4ft\u5feb4\u500d\u3002 vllm-project/vllm How continuous batching enables 23x throughput in LLM inference while reducing p50 latency [2023.08] SARATHI: Efficient LLM Inference by Piggybacking Decodes with Chunked Prefills Chunk Prefills LLM\u63a8\u7406\u4f18\u5316 - Chunked prefills [2022.05] FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness FlashAttention\uff0c\u63d0\u901f2.4\u500d 2.2.2. FFN # [2023.06] [MoE: An Efficient Mixture of Experts for Large Language Models](URL_ADDRESS- [2023.06] MoE: An Efficient Mixture of Experts for Large Language Models GEMM \u77e9\u9635\u7b97\u5b50\u4f18\u5316 DeepGEMM FP8\u77e9\u9635\u7b97\u5b50\u4f18\u5316 DeepEP \u4e13\u5bb6\u5e76\u884c 2.3. \u5206\u5e03\u5f0f\u4f18\u5316 # 3FS \u5206\u5e03\u5f0f\u6587\u4ef6\u7cfb\u7edf [2022.12] Overlap Communication with Dependent Computation via Decomposition in Large Deep Learning Models [2022.11] Efficiently Scaling Transformer Inference \u5927\u6a21\u578b\u5e76\u884c\u63a8\u7406\u7684\u592a\u7956\u957f\u62f3\uff1a\u89e3\u8bfbJeff Dean\u7f72\u540dMLSys 23\u6770\u51fa\u8bba\u6587 [2022.07] Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning \u5927\u6a21\u578b\u63a8\u7406\u5e8f\u5217\u5e76\u884c \u5e8f\u5217\u5e76\u884cDeepSpeed-FPDT","title":"Inference"},{"location":"3.%5B%E5%9F%BA%E5%BB%BA%5D%E6%95%88%E7%8E%87/Inference/#1","text":"LLM\u63a8\u7406\u4f18\u5316\u6280\u672f\u8be6\u89e3 \u63a8\u7406\u52a0\u901f\u65b9\u6cd5 github:vLLM \u9ad8\u6027\u80fd\u63a8\u7406\u6846\u67b6 NVIDIA/FasterTransformer \u5206\u6790transformer\u6a21\u578b\u7684\u53c2\u6570\u91cf\u3001\u8ba1\u7b97\u91cf\u3001\u4e2d\u95f4\u6fc0\u6d3b\u3001KV cache","title":"1. \u5927\u6a21\u578b\u63a8\u7406\u5b66\u4e60\u8d44\u6599"},{"location":"3.%5B%E5%9F%BA%E5%BB%BA%5D%E6%95%88%E7%8E%87/Inference/#2","text":"\u5927\u6a21\u578b\u63a8\u7406\u5173\u6ce8\uff1a\u5ef6\u8fdf\u3001\u541e\u5410\u548c\u6210\u672c\uff0c\u4f18\u5316\u5206\uff1a\u6539\u6a21\u578b\u53c2\u6570\u3001\u5355\u673a\u4f18\u5316\u3001\u5206\u5e03\u5f0f\u4f18\u5316\u3002 \u6539\u6a21\u578b\u53c2\u6570\u3002 \u91cf\u5316 attention\u7ed3\u6784(mha\u3001mqa\u3001mla\u3001sparse attention\u3001 liner attention) ffn\u7ed3\u6784(moe) \u5176\u4ed6\u7ed3\u6784(silu\u3001rmsnorm) \u968f\u673a\u89e3\u7801\u3002 \u5355\u673a\u4f18\u5316\u3002LLM\u662fio\u7ea6\u675f\u7684\u3002 \u7b97\u5b50\u878d\u5408\u3002qkv\u878d\u5408\uff0cbias\u878d\u5408\u3002 \u9ad8\u6027\u80fd\u7b97\u5b50\u3002flash attention\u3001\u9ad8\u6027\u80fd\u77e9\u9635\u8fd0\u7b97gemm\u3002\u9700\u8981\u6df1\u5165\u5230kernel\u5c42\u9762\u3002 \u5185\u5b58\u7ba1\u7406\u3002continuous batching\u3001paged attention\u3002 \u5206\u5e03\u5f0f\u4f18\u5316\u3002 \u6a21\u578b\u5e76\u884c\u3002tensor\u5e76\u884c\u3001pipeline\u5e76\u884c\u3001\u4e13\u5bb6\u5e76\u884c \u6570\u636e\u5e76\u884c\u3002zero3 \u786c\u4ef6\u7279\u5316\u3002prefill\u548cgenerate\u5206\u79bb\u3002","title":"2. \u5927\u6a21\u578b\u63a8\u7406\u4f18\u5316"},{"location":"3.%5B%E5%9F%BA%E5%BB%BA%5D%E6%95%88%E7%8E%87/Inference/#21","text":"","title":"2.1. \u6539\u6a21\u578b\u53c2\u6570"},{"location":"3.%5B%E5%9F%BA%E5%BB%BA%5D%E6%95%88%E7%8E%87/Inference/#211","text":"[2025.01] Qrazor: Reliable and Effortless 4-bit LLM Quantization by Significant Data Razoring [2023.10] LLM-FP4: 4-Bit Floating-Point Quantized Transformers [2023.09] Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs AutoRound intel/auto-round [2023.06] AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration AWQ [2022.10] GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers GPTQ [2022.08] LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale LLM.int8(): 8-bit\u91cf\u5316\u63a8\u7406","title":"2.1.1. \u91cf\u5316"},{"location":"3.%5B%E5%9F%BA%E5%BB%BA%5D%E6%95%88%E7%8E%87/Inference/#212_attention","text":"FlashMLA","title":"2.1.2. attention\u7ed3\u6784"},{"location":"3.%5B%E5%9F%BA%E5%BB%BA%5D%E6%95%88%E7%8E%87/Inference/#213","text":"[2024.01] EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty \u8bba\u6587\u89e3\u8bfb\u3011EAGLE\uff1a\u5728\u7279\u5f81\u5c42\u8fdb\u884c\u81ea\u56de\u5f52\u7684\u6295\u673a\u91c7\u6837\u6846\u67b6 [2024.01] Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads \u52a0\u591a\u4e2a\u89e3\u7801\u5934\uff0c\u7528topk\u89e3\u7801\u591a\u4e2atoken\uff0c\u7528tree attention\u5224\u5b9a\u662f\u5426\u91c7\u7eb3\u3002 [2023.10] Lookahead: An Inference Acceleration Framework for Large Language Model with Lossless Generation Accuracy \u75282D\u7a97\u53e3\u7ef4\u62a4\u591a\u4e2angram [2022.11] Fast Inference from Transformers via Speculative Decoding \u5c0f\u6a21\u578b\u9884\u4f30\uff0c\u5927\u6a21\u578b\u5224\u5b9a\u662f\u5426\u91c7\u7eb3\u3002\u8ba1\u7b97\u91cf\u4e0d\u53d8\uff0c\u4f46\u662f\u53ef\u4ee5\u5e76\u884c\u5316\u4e86\u3002","title":"2.1.3. \u5e76\u884c\u89e3\u7801"},{"location":"3.%5B%E5%9F%BA%E5%BB%BA%5D%E6%95%88%E7%8E%87/Inference/#22","text":"","title":"2.2. \u5355\u673a\u4f18\u5316"},{"location":"3.%5B%E5%9F%BA%E5%BB%BA%5D%E6%95%88%E7%8E%87/Inference/#221_attention","text":"[2023.09] Efficient Memory Management for Large Language Model Serving with PagedAttention PagedAttention,\u865a\u62df\u5185\u5b58\u6280\u672f\uff0c\u5206\u9875\u3002\u6bd4\u6734\u7d20batch\u5feb22\u500d\u541e\u5410\uff0c\u6bd4ft\u5feb4\u500d\u3002 vllm-project/vllm How continuous batching enables 23x throughput in LLM inference while reducing p50 latency [2023.08] SARATHI: Efficient LLM Inference by Piggybacking Decodes with Chunked Prefills Chunk Prefills LLM\u63a8\u7406\u4f18\u5316 - Chunked prefills [2022.05] FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness FlashAttention\uff0c\u63d0\u901f2.4\u500d","title":"2.2.1. attention"},{"location":"3.%5B%E5%9F%BA%E5%BB%BA%5D%E6%95%88%E7%8E%87/Inference/#222_ffn","text":"[2023.06] [MoE: An Efficient Mixture of Experts for Large Language Models](URL_ADDRESS- [2023.06] MoE: An Efficient Mixture of Experts for Large Language Models GEMM \u77e9\u9635\u7b97\u5b50\u4f18\u5316 DeepGEMM FP8\u77e9\u9635\u7b97\u5b50\u4f18\u5316 DeepEP \u4e13\u5bb6\u5e76\u884c","title":"2.2.2. FFN"},{"location":"3.%5B%E5%9F%BA%E5%BB%BA%5D%E6%95%88%E7%8E%87/Inference/#23","text":"3FS \u5206\u5e03\u5f0f\u6587\u4ef6\u7cfb\u7edf [2022.12] Overlap Communication with Dependent Computation via Decomposition in Large Deep Learning Models [2022.11] Efficiently Scaling Transformer Inference \u5927\u6a21\u578b\u5e76\u884c\u63a8\u7406\u7684\u592a\u7956\u957f\u62f3\uff1a\u89e3\u8bfbJeff Dean\u7f72\u540dMLSys 23\u6770\u51fa\u8bba\u6587 [2022.07] Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning \u5927\u6a21\u578b\u63a8\u7406\u5e8f\u5217\u5e76\u884c \u5e8f\u5217\u5e76\u884cDeepSpeed-FPDT","title":"2.3. \u5206\u5e03\u5f0f\u4f18\u5316"},{"location":"3.%5B%E5%9F%BA%E5%BB%BA%5D%E6%95%88%E7%8E%87/train/","text":"\u8bad\u7ec3\u6846\u67b6 # deepspeedai/DeepSpeed unslothai/unsloth Finetune\u6846\u67b6 \u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6846\u67b6 # [54.7k] hiyouga/LLaMA-Factory [14.7k] huggingface/trl [11.3k] volcengine/verl \u5b57\u8282 [8.8k] modelscope/ms-swift [7.4k] OpenRLHF/OpenRLHF [1.5k] alibaba/ROLL \u5206\u5e03\u5f0f\u8bad\u7ec3 # [2024.10] Liger Kernel: Efficient Triton Kernels for LLM Training linkedin/Liger-Kernel [2023.04] PyTorch FSDP: Experiences on Scaling Fully Sharded Data Parallel [2019.10] ZeRO: Memory Optimizations Toward Training Trillion Parameter Models [LLM]\u5927\u6a21\u578b\u663e\u5b58\u8ba1\u7b97\u516c\u5f0f\u4e0e\u4f18\u5316","title":"Train"},{"location":"3.%5B%E5%9F%BA%E5%BB%BA%5D%E6%95%88%E7%8E%87/train/#_1","text":"deepspeedai/DeepSpeed unslothai/unsloth Finetune\u6846\u67b6","title":"\u8bad\u7ec3\u6846\u67b6"},{"location":"3.%5B%E5%9F%BA%E5%BB%BA%5D%E6%95%88%E7%8E%87/train/#_2","text":"[54.7k] hiyouga/LLaMA-Factory [14.7k] huggingface/trl [11.3k] volcengine/verl \u5b57\u8282 [8.8k] modelscope/ms-swift [7.4k] OpenRLHF/OpenRLHF [1.5k] alibaba/ROLL","title":"\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6846\u67b6"},{"location":"3.%5B%E5%9F%BA%E5%BB%BA%5D%E6%95%88%E7%8E%87/train/#_3","text":"[2024.10] Liger Kernel: Efficient Triton Kernels for LLM Training linkedin/Liger-Kernel [2023.04] PyTorch FSDP: Experiences on Scaling Fully Sharded Data Parallel [2019.10] ZeRO: Memory Optimizations Toward Training Trillion Parameter Models [LLM]\u5927\u6a21\u578b\u663e\u5b58\u8ba1\u7b97\u516c\u5f0f\u4e0e\u4f18\u5316","title":"\u5206\u5e03\u5f0f\u8bad\u7ec3"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/Embedding/","text":"\u6587\u672cEmbedding\u6280\u672f # \u5b66\u4e60\u8d44\u6599 # sbert \u75281B\u4e2a\u5bf9\u6bd4\u5bf9\u8bad\u7ec3\u6700\u597d\u7684\u53e5\u5411\u91cf\u6a21\u578b \u6e90\u4e8e\u8fd9\u6837\u7684\u8ba4\u77e5\uff1a\u66f4\u591a\u66f4\u591a\u6837\u7684\u6570\u636e+\u66f4\u5927BatchSize\u53ef\u4ee5\u8bad\u7ec3\u51fa\u66f4\u597d\u7684Embedding\u6a21\u578b\u3002 sentence-transformers benchmark # MTEB\u8bc4\u4f30\u57fa\u51c6 mteb/leaderboard \u8bba\u6587 # \u57fa\u4e8eTransformer\u67b6\u6784 # [2025.03] Gemini Embedding: Generalizable Embeddings from Gemini google sota\u6548\u679c\u3002\u96be\u8d1f\u4f8b\u3001\u5408\u6210\u6570\u636e\u84b8\u998f\u5927\u6a21\u578b\u3001\u7528LLM\u521d\u59cb\u5316\u3002\u5f15\u5165task prompts and a pre-finetuning stage\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6548\u679c\u3002\u7528Model Soup\u6765\u878d\u5408\u591a\u4e2acheckpoint\u7684\u6548\u679c\u3002mean polling \u7136\u540e\u8fc7\u4e00\u4e2alinear\u5230\u76ee\u6807\u7ef4\u5ea6\u3002nce\u3002 [2024.09] C-Pack: Packed Resources For General Chinese Embeddings \u667a\u6e90\u5f00\u6e90\u3002\u5206\u4e09\u4e2a\u9636\u6bb5\uff1a\u9884\u8bad\u7ec3\u3001\u5bf9\u6bd4\u5bf9\u5b66\u4e60\u3001\u4efb\u52a1\u7cbe\u8c03\u3002\u9884\u8bad\u7ec3\u4f7f\u7528retroMAE\uff0c\u7528in-batch\u8d1f\u91c7\u6837\uff0cbatchsize 19200\uff0c\u4efb\u52a1\u7cbe\u8c03\u7528ann\u6311\u9009\u96be\u8d1f\u6837\u672c\u3002 FlagEmbedding bge-large-zh-v1.5 bge-reranker-large [2022.10] RetroMAE: Pre-Training Retrieval-oriented Language Models Via Masked Auto-Encoder [2023.08] Towards General Text Embeddings with Multi-stage Contrastive Learning \u963f\u91cc\u5f00\u6e90\u3002infoNCE\u3002mean polling\uff0c\u4e24\u9636\u6bb5\uff1a\u5927batchsize\u7684in-batch\u8bad\u7ec3\u3002\u96be\u8d1f\u6837\u672c\u8bad\u7ec3\u3002 gte-large-zh [2022.08] https://arxiv.org/pdf/2202.08904v5 \u6e05\u534e\uff0c\u5bf9\u6bd4\u4e86 cross-encoder vs bi-encoder\uff0c\u4f7f\u7528\u4f4d\u7f6e\u52a0\u6743\u7684mean polling\uff0c\u53ea\u662ffine-tunning\u4e86bias [2022.01] Text and Code Embeddings by Contrastive Pre-Training openai 1. \u9884\u8bad\u7ec3\u6a21\u578b\u4f5c\u4e3a\u521d\u59cb\u5316\u6a21\u578b 2. \u5927batch\u7684\u5bf9\u6bd4\u5b66\u4e60logit\uff0c\u76f8\u4f3c\u5ea6+\u4ea4\u53c9\u71b5+in-batch\u8d1f\u91c7\u6837 3. Fine-tuning (\u975e\u5fc5\u987b) [2021.04] SimCSE: Simple Contrastive Learning of Sentence Embeddings github:SimCSE [2020.09] Dense Passage Retrieval for Open-Domain Question Answering meta https://huggingface.co/docs/transformers/model_doc/dpr#overview github:DPR \u8bad\u7ec3\u6280\u672f # 1. \u76ee\u6807\u51fd\u6570 # \u5bf9\u6bd4\u635f\u5931(Contrastive Loss) \u4e09\u91cd\u635f\u5931(Triplet Loss) \u4f59\u5f26\u76f8\u4f3c\u5ea6\u635f\u5931 2. \u6570\u636e\u589e\u5f3a # \u56de\u8bd1(Back Translation) \u8bcd\u8bed\u5220\u9664/\u66ff\u6362 \u5bf9\u6297\u6837\u672c\u751f\u6210 \u96be\u4f8b\u6316\u6398(Hard Negative Mining) \u5408\u6210\u6570\u636e [2024.5] Improving Text Embeddings with Large Language Models \u7528LLM\u5408\u621093\u79cd\u8bed\u8a00\u7684finetune\u6570\u636e\u3002 [2024.03] Gecko: Versatile Text Embeddings Distilled from Large Language Models \u4eceLLM\u84b8\u998f\u77e5\u8bc6\u3002\u7528LLM\u751f\u6210QA\u5bf9\uff0c\u7136\u540e\u5bf9\u6bcf\u4e00\u4e2aquery\u7cbe\u6311A\uff0c\u6807\u6ce8\u6b63\u4f8b\u548c\u96be\u8d1f\u4f8b\u3002 [2022.09] Promptagator: Few-shot Dense Retrieval From 8 Examples \u7528few-shot\u7684prompt\u6765\u751f\u6210query 3. \u8bad\u7ec3\u6280\u5de7 # \u5c42\u5f52\u4e00\u5316\u7b56\u7565 \u6e29\u5ea6\u7cfb\u6570\u8c03\u8282 \u8f93\u51fa\u7ef4\u5ea6 [2022.04] Matryoshka Representation Learning \u7528\u4e00\u4e2aEmbedding\u4e0a\u6784\u5efa\u4e0d\u540c\u7684loss\uff0c\u6bcf\u4e2aloss\u4f7f\u7528\u4e0d\u540c\u6570\u91cf\u548c\u7ec4\u5408\u7684\u7ef4\u5ea6\u3002 \u8bc4\u4f30\u6307\u6807 # \u6307\u6807\u540d\u79f0 \u8bf4\u660e \u5178\u578b\u6570\u636e\u96c6 Spearman\u76f8\u5173\u6027 \u6392\u540d\u76f8\u5173\u6027 STS-B Recall@K \u68c0\u7d22\u53ec\u56de\u7387 MS-MARCO \u805a\u7c7b\u7eaf\u5ea6 \u805a\u7c7b\u6548\u679c\u8bc4\u4f30 AG News","title":"Embedding"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/Embedding/#embedding","text":"","title":"\u6587\u672cEmbedding\u6280\u672f"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/Embedding/#_1","text":"sbert \u75281B\u4e2a\u5bf9\u6bd4\u5bf9\u8bad\u7ec3\u6700\u597d\u7684\u53e5\u5411\u91cf\u6a21\u578b \u6e90\u4e8e\u8fd9\u6837\u7684\u8ba4\u77e5\uff1a\u66f4\u591a\u66f4\u591a\u6837\u7684\u6570\u636e+\u66f4\u5927BatchSize\u53ef\u4ee5\u8bad\u7ec3\u51fa\u66f4\u597d\u7684Embedding\u6a21\u578b\u3002 sentence-transformers","title":"\u5b66\u4e60\u8d44\u6599"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/Embedding/#benchmark","text":"MTEB\u8bc4\u4f30\u57fa\u51c6 mteb/leaderboard","title":"benchmark"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/Embedding/#_2","text":"","title":"\u8bba\u6587"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/Embedding/#transformer","text":"[2025.03] Gemini Embedding: Generalizable Embeddings from Gemini google sota\u6548\u679c\u3002\u96be\u8d1f\u4f8b\u3001\u5408\u6210\u6570\u636e\u84b8\u998f\u5927\u6a21\u578b\u3001\u7528LLM\u521d\u59cb\u5316\u3002\u5f15\u5165task prompts and a pre-finetuning stage\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6548\u679c\u3002\u7528Model Soup\u6765\u878d\u5408\u591a\u4e2acheckpoint\u7684\u6548\u679c\u3002mean polling \u7136\u540e\u8fc7\u4e00\u4e2alinear\u5230\u76ee\u6807\u7ef4\u5ea6\u3002nce\u3002 [2024.09] C-Pack: Packed Resources For General Chinese Embeddings \u667a\u6e90\u5f00\u6e90\u3002\u5206\u4e09\u4e2a\u9636\u6bb5\uff1a\u9884\u8bad\u7ec3\u3001\u5bf9\u6bd4\u5bf9\u5b66\u4e60\u3001\u4efb\u52a1\u7cbe\u8c03\u3002\u9884\u8bad\u7ec3\u4f7f\u7528retroMAE\uff0c\u7528in-batch\u8d1f\u91c7\u6837\uff0cbatchsize 19200\uff0c\u4efb\u52a1\u7cbe\u8c03\u7528ann\u6311\u9009\u96be\u8d1f\u6837\u672c\u3002 FlagEmbedding bge-large-zh-v1.5 bge-reranker-large [2022.10] RetroMAE: Pre-Training Retrieval-oriented Language Models Via Masked Auto-Encoder [2023.08] Towards General Text Embeddings with Multi-stage Contrastive Learning \u963f\u91cc\u5f00\u6e90\u3002infoNCE\u3002mean polling\uff0c\u4e24\u9636\u6bb5\uff1a\u5927batchsize\u7684in-batch\u8bad\u7ec3\u3002\u96be\u8d1f\u6837\u672c\u8bad\u7ec3\u3002 gte-large-zh [2022.08] https://arxiv.org/pdf/2202.08904v5 \u6e05\u534e\uff0c\u5bf9\u6bd4\u4e86 cross-encoder vs bi-encoder\uff0c\u4f7f\u7528\u4f4d\u7f6e\u52a0\u6743\u7684mean polling\uff0c\u53ea\u662ffine-tunning\u4e86bias [2022.01] Text and Code Embeddings by Contrastive Pre-Training openai 1. \u9884\u8bad\u7ec3\u6a21\u578b\u4f5c\u4e3a\u521d\u59cb\u5316\u6a21\u578b 2. \u5927batch\u7684\u5bf9\u6bd4\u5b66\u4e60logit\uff0c\u76f8\u4f3c\u5ea6+\u4ea4\u53c9\u71b5+in-batch\u8d1f\u91c7\u6837 3. Fine-tuning (\u975e\u5fc5\u987b) [2021.04] SimCSE: Simple Contrastive Learning of Sentence Embeddings github:SimCSE [2020.09] Dense Passage Retrieval for Open-Domain Question Answering meta https://huggingface.co/docs/transformers/model_doc/dpr#overview github:DPR","title":"\u57fa\u4e8eTransformer\u67b6\u6784"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/Embedding/#_3","text":"","title":"\u8bad\u7ec3\u6280\u672f"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/Embedding/#1","text":"\u5bf9\u6bd4\u635f\u5931(Contrastive Loss) \u4e09\u91cd\u635f\u5931(Triplet Loss) \u4f59\u5f26\u76f8\u4f3c\u5ea6\u635f\u5931","title":"1. \u76ee\u6807\u51fd\u6570"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/Embedding/#2","text":"\u56de\u8bd1(Back Translation) \u8bcd\u8bed\u5220\u9664/\u66ff\u6362 \u5bf9\u6297\u6837\u672c\u751f\u6210 \u96be\u4f8b\u6316\u6398(Hard Negative Mining) \u5408\u6210\u6570\u636e [2024.5] Improving Text Embeddings with Large Language Models \u7528LLM\u5408\u621093\u79cd\u8bed\u8a00\u7684finetune\u6570\u636e\u3002 [2024.03] Gecko: Versatile Text Embeddings Distilled from Large Language Models \u4eceLLM\u84b8\u998f\u77e5\u8bc6\u3002\u7528LLM\u751f\u6210QA\u5bf9\uff0c\u7136\u540e\u5bf9\u6bcf\u4e00\u4e2aquery\u7cbe\u6311A\uff0c\u6807\u6ce8\u6b63\u4f8b\u548c\u96be\u8d1f\u4f8b\u3002 [2022.09] Promptagator: Few-shot Dense Retrieval From 8 Examples \u7528few-shot\u7684prompt\u6765\u751f\u6210query","title":"2. \u6570\u636e\u589e\u5f3a"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/Embedding/#3","text":"\u5c42\u5f52\u4e00\u5316\u7b56\u7565 \u6e29\u5ea6\u7cfb\u6570\u8c03\u8282 \u8f93\u51fa\u7ef4\u5ea6 [2022.04] Matryoshka Representation Learning \u7528\u4e00\u4e2aEmbedding\u4e0a\u6784\u5efa\u4e0d\u540c\u7684loss\uff0c\u6bcf\u4e2aloss\u4f7f\u7528\u4e0d\u540c\u6570\u91cf\u548c\u7ec4\u5408\u7684\u7ef4\u5ea6\u3002","title":"3. \u8bad\u7ec3\u6280\u5de7"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/Embedding/#_4","text":"\u6307\u6807\u540d\u79f0 \u8bf4\u660e \u5178\u578b\u6570\u636e\u96c6 Spearman\u76f8\u5173\u6027 \u6392\u540d\u76f8\u5173\u6027 STS-B Recall@K \u68c0\u7d22\u53ec\u56de\u7387 MS-MARCO \u805a\u7c7b\u7eaf\u5ea6 \u805a\u7c7b\u6548\u679c\u8bc4\u4f30 AG News","title":"\u8bc4\u4f30\u6307\u6807"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PostTraining/","text":"1. \u5927\u6a21\u578b\u540e\u8bad\u7ec3\u6280\u672f # 1.1. \u5b66\u4e60\u8d44\u6599 # huggingface-llm-course HuggingFace\u7684LLM\u8bfe\u7a0b\uff0c\u4e3b\u8981\u770b\u4e8611\u7ae0\u5bf9\u9f50\u548c12\u7ae0\u63a8\u7406\u6a21\u578b\u3002 huggingface-smol-course HuggingFace\u7684SMOL\u8bfe\u7a0b\uff0c\u7528\u5c0f\u6a21\u578b\u5b66\u4e60\u5bf9\u9f50\u6280\u672f \u5de5\u4e1a\u754c\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u540e\u8bad\u7ec3(Post-Training)\u6280\u672f\u603b\u7ed3 \u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3\u5927\u6a21\u578b 1.2. \u5f00\u6e90\u5de5\u5177 # TRL HuggingFace RLHF\u5de5\u5177\u5e93 DeepSpeed-Chat \u5fae\u8f6fRLHF\u5b9e\u73b0 verl \u706b\u5c71\u5f15\u64ceRLHF\u5b9e\u73b0 open-r1 OpenRLHF 1.3. \u7814\u7a76\u673a\u6784 # Sea AI Lab sea\u7684ai\u5b9e\u9a8c\u5ba4\uff0c\u65b0\u52a0\u5761 github:sail-sg 1.4. \u6838\u5fc3\u6a21\u5757 # 1.4.1. \u5bf9\u9f50\u7b97\u6cd5 # 1.4.1.1. SFT # [2023.08] Aligning Language Models with Offline Learning from Human Feedback conditional-sft \u4e0d\u540c\u7684\u6837\u672c\u6709\u4e0d\u540c\u7684\u6743\u91cd 1.4.1.2. PEFT # \u76f8\u5173\u8d44\u6599\uff1a huggingface:peft \u5927\u6a21\u578b\u53c2\u6570\u9ad8\u6548\u5fae\u8c03(PEFT) \u7b97\u6cd5\uff1a LORA QLORA Adapter Prefix Tuning Prompt Tuning BitFit 1.4.1.3. DPO # [2024.05] Exploratory Preference Optimization: Harnessing Implicit Q*-Approximation for Sample-Efficient RLHF XPO\u5728Online DPO\u57fa\u7840\u4e0a\u5728loss\u4e0a\u52a0\u4e86\u9f13\u52b1\u63a2\u7d22\u7684\u6b63\u5219\u9879\u3002 [2024.04] Binary Classifier Optimization for Large Language Model Alignment BCO\u7528BCE\u3002\u5956\u52b1\u8f6c\u79fb\u3001\u5e95\u5c42\u5206\u5e03\u5339\u914d\u3002 [2024.03] ORPO: Monolithic Preference Optimization without Reference Model DPO\u57fa\u7840\u4e0a\u53bb\u6389reference model\u3002 [2024.02] Direct Language Model Alignment from Online AI Feedback Online DPO\u200b \u7ed3\u5408\u5728\u7ebf\u6570\u636e\u66f4\u65b0\uff0c\u52a8\u6001\u8c03\u6574\u504f\u597d\u6570\u636e\u96c6\uff0c\u7f13\u89e3\u5206\u5e03\u504f\u79fb\u3002\u7528LLM+Prompt\u5b9e\u65f6\u5bf9\u6837\u672c\u6253\u6807\u5f97\u5230\u5bf9\u6bd4\u5bf9\u3002 [2024.02] KTO: Model Alignment as Prospect Theoretic Optimization \u57fa\u4e8e\u524d\u666f\u7406\u8bba\uff0c\u76f4\u63a5\u4f18\u5316\u4eba\u7c7b\u611f\u77e5\u6548\u7528\uff0c\u66ff\u4ee3\u4f20\u7edf\u504f\u597d\u5bf9\u6570\u4f3c\u7136 ContextualAI/HALOs [2024.01] Contrastive Preference Optimization: Pushing the Boundaries of LLM Performance in Machine Translation CPO\u662f\u8d1f\u5bf9\u6570\u4f3c\u7136\u635f\u5931+\u504f\u597d\u635f\u5931\u3002 [2023.12] Nash Learning from Human Feedback \u5728act\u548cref\u7684\u6a21\u578b\u4e0a\u5206\u522b\u5f97\u5230logit\u7136\u540e\u52a0\u6743\u6c42\u548c\u5f97\u5230\u989d\u5916\u7b56\u7565\u3002 [2023.10] A General Theoretical Paradigm to Understand Learning from Human Preferences IPO\u76f8\u5f53\u4e8e \u5728DPO\u7684\u635f\u5931\u51fd\u6570\u4e0a\u6dfb\u52a0\u4e86\u4e00\u4e2a\u6b63\u5219\u9879 [2023.05] Direct Preference Optimization: Your Language Model is Secretly a Reward Model / \u3010\u7b14\u8bb0\u3011 \u901a\u8fc7\u504f\u597d\u6570\u636e\u76f4\u63a5\u4f18\u5316\u7b56\u7565\uff0c\u7ed5\u8fc7\u663e\u5f0f\u5956\u52b1\u5efa\u6a21 DPO\u4e3a\u4ec0\u4e48\u4f1a\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u53d8\u957f \u5927\u6a21\u578b\u5bf9\u9f50\u65b9\u6cd5\u7b14\u8bb0\u4e00\uff1aDPO\u53ca\u5176\u53d8\u79cdIPO\u3001KTO\u3001CPO \u4e00\u6587\u770b\u5c3dLLM\u5bf9\u9f50\u6280\u672f\uff1aRLHF\u3001RLAIF\u3001PPO\u3001DPO\u2026\u2026 1.4.1.4. RL # [2025.04] Seed1.5-Thinking: Advancing Superb Reasoning Models with Reinforcement Learning [2025.04] A Minimalist Approach to LLM Reasoning: from Rejection Sampling to Reinforce RAFT++\uff0c GRPO=\u9ad8\u7ea7\u7248\u62d2\u7edd\u91c7\u6837\uff1f\u5f3a\u5316\u5b66\u4e60\u795b\u9b45\u65f6\u523b\uff1a\u8d1f\u6837\u672c\u201c\u53bb\u829c\u5b58\u83c1\u201d\u624d\u662f\u5173\u952e\uff01 [2025.04] VAPO: Efficient and Reliable Reinforcement Learning for Advanced Reasoning Tasks VAPO,seed,\u52a0\u4e0avalue function\u3002 [2025.03] DAPO: An Open-Source LLM Reinforcement Learning System at Scale DAPO,seed,\u8c03\u9ad8clip\u4e0a\u754c\uff0c\u52a8\u6001\u91c7\u6837\u53bb\u6389reward\u4e3a1\u7684prompt\uff0csoft\u8d85\u957f\u60e9\u7f5a\uff0c\u53bb\u6389kl [2025.03] What's Behind PPO's Collapse in Long-CoT? Value Optimization Holds the Secret VC-PPO, \u5b57\u8282seed\u3002long-cot\u7684\u95ee\u9898\u5728\u4e8evalue\u4f30\u8ba1\u4e0d\u51c6\uff0c\u9760\u540e\u7684token\u7684V\u5927\uff0cA\u5c0f\u3002V\u505a\u9884\u8bad\u7ec3\uff0c\u7528lamada=1\u3002Policy\u5b66\u4e60\u7684\u65f6\u5019\u5bf9\u5e94\u7684A\u7528lamada=0.95\u51cf\u5c11\u65b9\u5dee\uff0c\u56e0\u4e3aA\u4e0d\u4f1a\u56e0\u4e3aV\u7684\u5f15\u5165bias\u3002 [2025.03] Understanding R1-Zero-Like Training: A Critical Perspective Dr.GRPO sail-sg/understand-r1-zero [2025.02] Process Reinforcement through Implicit Rewards PRIME \u3010\u8bba\u6587\u89e3\u8bfb\u3011PRIME\uff1a\u901a\u8fc7\u300c\u9690\u5f0f\u8fc7\u7a0b\u5956\u52b1\u300d\u6765\u63d0\u5347LLM\u7684\u63a8\u7406\u80fd\u529b [2025.01] REINFORCE++: An Efficient RLHF Algorithm with Robustness to Both Prompt and Reward Models \u5728batch\u5185\u5f52\u4e00\u5316\uff0c\u7528kl\u6563\u5ea6\u4f5c\u4e3a\u6b63\u5219\u9879\u3002 [2025.02] Logic-RL: Unleashing LLM Reasoning with Rule-Based Reinforcement Learning Logic-RL\uff1a\u57fa\u4e8e\u89c4\u5219\u5f3a\u5316\u5b66\u4e60\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7a81\u7834 [2024.07] ReaL: Efficient RLHF Training of Large Language Models with Parameter Reallocation [2024.04] DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models [2024.02] Back to Basics: Revisiting REINFORCE Style Optimization for Learning from Human Feedback in LLMs RLOO,\u907f\u514d\u4f7f\u7528value model\u548cGAE\uff0c\u51cf\u5c11\u663e\u5b58\u5360\u7528\uff0c\u7559\u4e00\u6cd5\u505a\u5f52\u4e00\u5316 [2024.01] ReFT: Reasoning with Reinforced Fine-Tuning REFT\u3002\u4f7f\u7528\u8ddfSFT\u4e00\u6837\u7684\u6570\u636e\uff0c\u53ea\u662f\u4f1a\u91c7\u6837\u66f4\u591acot\uff0c\u7136\u540e\u7528PPO\u4f18\u5316\u3002 [2023.10] ReMax: A Simple, Effective, and Efficient Reinforcement Learning Method for Aligning Large Language Models Remax, \u7528\u8d2a\u5a6a\u91c7\u6837\u4f5c\u4e3abase\u3002 [2023.07] Secrets of RLHF in Large Language Models Part I: PPO PPO-max PPO\u63a2\u7d22\uff08\u5982\u4f55\u5b9e\u73b0\u7a33\u5b9a\u8bad\u7ec3\uff09 [2023.05] Let's Verify Step by Step [2023.03] Self-Refine: Iterative Refinement with Self-Feedback \u7528few-shot\u5f97\u5230feedback\uff0c\u7136\u540e\u4f18\u5316\u56de\u7b54\u3002 [2022.12] Constitutional AI: Harmlessness from AI Feedback [2022.11] Solving math word problems with process- and outcome-based feedback [2022.04] Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback [2018.06] Self-Imitation Learning [2017.07] Proximal Policy Optimization Algorithms 1.4.1.5. \u63a8\u7406\u548c\u5de5\u5177 # [2022.11] PAL: Program-aided Language Models PAL [2022.10] ReAct: Synergizing Reasoning and Acting in Language Models ReAct\uff0cGoogle\uff0cquery\u3001think\u3001action\u3001result\u3002 1.4.1.6. \u84b8\u998f # [2023.06] On-Policy Distillation of Language Models: Learning from Self-Generated Mistakes GKD\u89e3\u51b3\u8bad\u63a8\u4e0d\u4e00\u81f4\u95ee\u9898\u3002 1.4.2. Reward Model # [2025.04] Inference-Time Scaling for Generalist Reward Modeling / \u3010\u8bba\u6587\u89e3\u8bfb\u3011 SPCT \u8ba9\u6a21\u578b\u81ea\u5df1\u751f\u6210\u539f\u5219\uff0c\u7136\u540e\u751f\u6210\u6253\u5206\u3002 [2024.10] Generative Reward Models \u65af\u5766\u798f\uff0c\u5408\u6210\u5b9e\u9a8c\u5ba4\uff0cCoT-GenRM\uff0c\u5148\u901a\u8fc7prompt\u8ba9\u6a21\u578b\u7ed9Q\u751f\u6210\u63a8\u7406\u548cA\u6807\u8bb0\u51fa\u6b63\u786e\u7684\uff0c\u6216\u7ed9\u5b9aQ\u548cA\u751f\u6210\u63a8\u7406\u94fe\u3002\u7528\u5f97\u5230\u7684\u63a8\u7406\u6570\u636e\u505asft\u548cdpo\u3002\u5728\u96be\u5f97\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u66f4\u597d\u3002 [2024.08] Generative Verifiers: Reward Modeling as Next-Token Prediction \u8c37\u6b4c\uff0cdeepmind\uff0cCot-GenRM\uff0c\u53ea\u505a\u4e86sft [2024.06] HelpSteer2: Open-source dataset for training top-performing reward models nvidia/HelpSteer2 NVIDIA/NeMo-Aligner [2024.03] RewardBench: Evaluating Reward Models for Language Modeling allenai/reward-bench [2024.01] Secrets of RLHF in Large Language Models Part II: Reward Modeling \u590d\u65e6\u5927\u5b66\u90b1\u9521\u9e4f\u8001\u5e08\u6587\u7ae0\u89e3\u8bfb\uff1aSecrets of RLHF in Large Language Models Part II: Reward Modeling [2023.06] PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization WeOpenML/PandaLM 1.5. \u7ec6\u5206\u65b9\u5411 # 1.5.1. \u5f62\u5f0f\u5316\u8bc1\u660e # [2025.04] Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning MiniF2F-test 80+% [2025.04] Leanabell-Prover: Posttraining Scaling in Formal Reasoning MiniF2F-test 59.8% [2024.08] DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search miniF2F-test\u8fbe\u523063.5% github:DeepSeek-Prover-V1.5 1.5.2. \u89d2\u8272\u626e\u6f14 # [2023.03] Rewarding Chatbots for Real-World Engagement with Millions of Users Chai\u7684\u8bba\u6587\uff0c\u7528RLHF\u4f18\u5316Chatbot 1.6. \u7406\u89e3\u5bf9\u9f50 # LLM \u80fd\u4ece\u5355\u4e2a\u4f8b\u5b50\u4e2d\u5b66\u4e60\u5417\uff1f","title":"PostTraining"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PostTraining/#1","text":"","title":"1. \u5927\u6a21\u578b\u540e\u8bad\u7ec3\u6280\u672f"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PostTraining/#11","text":"huggingface-llm-course HuggingFace\u7684LLM\u8bfe\u7a0b\uff0c\u4e3b\u8981\u770b\u4e8611\u7ae0\u5bf9\u9f50\u548c12\u7ae0\u63a8\u7406\u6a21\u578b\u3002 huggingface-smol-course HuggingFace\u7684SMOL\u8bfe\u7a0b\uff0c\u7528\u5c0f\u6a21\u578b\u5b66\u4e60\u5bf9\u9f50\u6280\u672f \u5de5\u4e1a\u754c\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u540e\u8bad\u7ec3(Post-Training)\u6280\u672f\u603b\u7ed3 \u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3\u5927\u6a21\u578b","title":"1.1. \u5b66\u4e60\u8d44\u6599"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PostTraining/#12","text":"TRL HuggingFace RLHF\u5de5\u5177\u5e93 DeepSpeed-Chat \u5fae\u8f6fRLHF\u5b9e\u73b0 verl \u706b\u5c71\u5f15\u64ceRLHF\u5b9e\u73b0 open-r1 OpenRLHF","title":"1.2. \u5f00\u6e90\u5de5\u5177"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PostTraining/#13","text":"Sea AI Lab sea\u7684ai\u5b9e\u9a8c\u5ba4\uff0c\u65b0\u52a0\u5761 github:sail-sg","title":"1.3. \u7814\u7a76\u673a\u6784"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PostTraining/#14","text":"","title":"1.4. \u6838\u5fc3\u6a21\u5757"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PostTraining/#141","text":"","title":"1.4.1. \u5bf9\u9f50\u7b97\u6cd5"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PostTraining/#1411_sft","text":"[2023.08] Aligning Language Models with Offline Learning from Human Feedback conditional-sft \u4e0d\u540c\u7684\u6837\u672c\u6709\u4e0d\u540c\u7684\u6743\u91cd","title":"1.4.1.1. SFT"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PostTraining/#1412_peft","text":"\u76f8\u5173\u8d44\u6599\uff1a huggingface:peft \u5927\u6a21\u578b\u53c2\u6570\u9ad8\u6548\u5fae\u8c03(PEFT) \u7b97\u6cd5\uff1a LORA QLORA Adapter Prefix Tuning Prompt Tuning BitFit","title":"1.4.1.2. PEFT"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PostTraining/#1413_dpo","text":"[2024.05] Exploratory Preference Optimization: Harnessing Implicit Q*-Approximation for Sample-Efficient RLHF XPO\u5728Online DPO\u57fa\u7840\u4e0a\u5728loss\u4e0a\u52a0\u4e86\u9f13\u52b1\u63a2\u7d22\u7684\u6b63\u5219\u9879\u3002 [2024.04] Binary Classifier Optimization for Large Language Model Alignment BCO\u7528BCE\u3002\u5956\u52b1\u8f6c\u79fb\u3001\u5e95\u5c42\u5206\u5e03\u5339\u914d\u3002 [2024.03] ORPO: Monolithic Preference Optimization without Reference Model DPO\u57fa\u7840\u4e0a\u53bb\u6389reference model\u3002 [2024.02] Direct Language Model Alignment from Online AI Feedback Online DPO\u200b \u7ed3\u5408\u5728\u7ebf\u6570\u636e\u66f4\u65b0\uff0c\u52a8\u6001\u8c03\u6574\u504f\u597d\u6570\u636e\u96c6\uff0c\u7f13\u89e3\u5206\u5e03\u504f\u79fb\u3002\u7528LLM+Prompt\u5b9e\u65f6\u5bf9\u6837\u672c\u6253\u6807\u5f97\u5230\u5bf9\u6bd4\u5bf9\u3002 [2024.02] KTO: Model Alignment as Prospect Theoretic Optimization \u57fa\u4e8e\u524d\u666f\u7406\u8bba\uff0c\u76f4\u63a5\u4f18\u5316\u4eba\u7c7b\u611f\u77e5\u6548\u7528\uff0c\u66ff\u4ee3\u4f20\u7edf\u504f\u597d\u5bf9\u6570\u4f3c\u7136 ContextualAI/HALOs [2024.01] Contrastive Preference Optimization: Pushing the Boundaries of LLM Performance in Machine Translation CPO\u662f\u8d1f\u5bf9\u6570\u4f3c\u7136\u635f\u5931+\u504f\u597d\u635f\u5931\u3002 [2023.12] Nash Learning from Human Feedback \u5728act\u548cref\u7684\u6a21\u578b\u4e0a\u5206\u522b\u5f97\u5230logit\u7136\u540e\u52a0\u6743\u6c42\u548c\u5f97\u5230\u989d\u5916\u7b56\u7565\u3002 [2023.10] A General Theoretical Paradigm to Understand Learning from Human Preferences IPO\u76f8\u5f53\u4e8e \u5728DPO\u7684\u635f\u5931\u51fd\u6570\u4e0a\u6dfb\u52a0\u4e86\u4e00\u4e2a\u6b63\u5219\u9879 [2023.05] Direct Preference Optimization: Your Language Model is Secretly a Reward Model / \u3010\u7b14\u8bb0\u3011 \u901a\u8fc7\u504f\u597d\u6570\u636e\u76f4\u63a5\u4f18\u5316\u7b56\u7565\uff0c\u7ed5\u8fc7\u663e\u5f0f\u5956\u52b1\u5efa\u6a21 DPO\u4e3a\u4ec0\u4e48\u4f1a\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u53d8\u957f \u5927\u6a21\u578b\u5bf9\u9f50\u65b9\u6cd5\u7b14\u8bb0\u4e00\uff1aDPO\u53ca\u5176\u53d8\u79cdIPO\u3001KTO\u3001CPO \u4e00\u6587\u770b\u5c3dLLM\u5bf9\u9f50\u6280\u672f\uff1aRLHF\u3001RLAIF\u3001PPO\u3001DPO\u2026\u2026","title":"1.4.1.3. DPO"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PostTraining/#1414_rl","text":"[2025.04] Seed1.5-Thinking: Advancing Superb Reasoning Models with Reinforcement Learning [2025.04] A Minimalist Approach to LLM Reasoning: from Rejection Sampling to Reinforce RAFT++\uff0c GRPO=\u9ad8\u7ea7\u7248\u62d2\u7edd\u91c7\u6837\uff1f\u5f3a\u5316\u5b66\u4e60\u795b\u9b45\u65f6\u523b\uff1a\u8d1f\u6837\u672c\u201c\u53bb\u829c\u5b58\u83c1\u201d\u624d\u662f\u5173\u952e\uff01 [2025.04] VAPO: Efficient and Reliable Reinforcement Learning for Advanced Reasoning Tasks VAPO,seed,\u52a0\u4e0avalue function\u3002 [2025.03] DAPO: An Open-Source LLM Reinforcement Learning System at Scale DAPO,seed,\u8c03\u9ad8clip\u4e0a\u754c\uff0c\u52a8\u6001\u91c7\u6837\u53bb\u6389reward\u4e3a1\u7684prompt\uff0csoft\u8d85\u957f\u60e9\u7f5a\uff0c\u53bb\u6389kl [2025.03] What's Behind PPO's Collapse in Long-CoT? Value Optimization Holds the Secret VC-PPO, \u5b57\u8282seed\u3002long-cot\u7684\u95ee\u9898\u5728\u4e8evalue\u4f30\u8ba1\u4e0d\u51c6\uff0c\u9760\u540e\u7684token\u7684V\u5927\uff0cA\u5c0f\u3002V\u505a\u9884\u8bad\u7ec3\uff0c\u7528lamada=1\u3002Policy\u5b66\u4e60\u7684\u65f6\u5019\u5bf9\u5e94\u7684A\u7528lamada=0.95\u51cf\u5c11\u65b9\u5dee\uff0c\u56e0\u4e3aA\u4e0d\u4f1a\u56e0\u4e3aV\u7684\u5f15\u5165bias\u3002 [2025.03] Understanding R1-Zero-Like Training: A Critical Perspective Dr.GRPO sail-sg/understand-r1-zero [2025.02] Process Reinforcement through Implicit Rewards PRIME \u3010\u8bba\u6587\u89e3\u8bfb\u3011PRIME\uff1a\u901a\u8fc7\u300c\u9690\u5f0f\u8fc7\u7a0b\u5956\u52b1\u300d\u6765\u63d0\u5347LLM\u7684\u63a8\u7406\u80fd\u529b [2025.01] REINFORCE++: An Efficient RLHF Algorithm with Robustness to Both Prompt and Reward Models \u5728batch\u5185\u5f52\u4e00\u5316\uff0c\u7528kl\u6563\u5ea6\u4f5c\u4e3a\u6b63\u5219\u9879\u3002 [2025.02] Logic-RL: Unleashing LLM Reasoning with Rule-Based Reinforcement Learning Logic-RL\uff1a\u57fa\u4e8e\u89c4\u5219\u5f3a\u5316\u5b66\u4e60\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7a81\u7834 [2024.07] ReaL: Efficient RLHF Training of Large Language Models with Parameter Reallocation [2024.04] DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models [2024.02] Back to Basics: Revisiting REINFORCE Style Optimization for Learning from Human Feedback in LLMs RLOO,\u907f\u514d\u4f7f\u7528value model\u548cGAE\uff0c\u51cf\u5c11\u663e\u5b58\u5360\u7528\uff0c\u7559\u4e00\u6cd5\u505a\u5f52\u4e00\u5316 [2024.01] ReFT: Reasoning with Reinforced Fine-Tuning REFT\u3002\u4f7f\u7528\u8ddfSFT\u4e00\u6837\u7684\u6570\u636e\uff0c\u53ea\u662f\u4f1a\u91c7\u6837\u66f4\u591acot\uff0c\u7136\u540e\u7528PPO\u4f18\u5316\u3002 [2023.10] ReMax: A Simple, Effective, and Efficient Reinforcement Learning Method for Aligning Large Language Models Remax, \u7528\u8d2a\u5a6a\u91c7\u6837\u4f5c\u4e3abase\u3002 [2023.07] Secrets of RLHF in Large Language Models Part I: PPO PPO-max PPO\u63a2\u7d22\uff08\u5982\u4f55\u5b9e\u73b0\u7a33\u5b9a\u8bad\u7ec3\uff09 [2023.05] Let's Verify Step by Step [2023.03] Self-Refine: Iterative Refinement with Self-Feedback \u7528few-shot\u5f97\u5230feedback\uff0c\u7136\u540e\u4f18\u5316\u56de\u7b54\u3002 [2022.12] Constitutional AI: Harmlessness from AI Feedback [2022.11] Solving math word problems with process- and outcome-based feedback [2022.04] Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback [2018.06] Self-Imitation Learning [2017.07] Proximal Policy Optimization Algorithms","title":"1.4.1.4. RL"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PostTraining/#1415","text":"[2022.11] PAL: Program-aided Language Models PAL [2022.10] ReAct: Synergizing Reasoning and Acting in Language Models ReAct\uff0cGoogle\uff0cquery\u3001think\u3001action\u3001result\u3002","title":"1.4.1.5. \u63a8\u7406\u548c\u5de5\u5177"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PostTraining/#1416","text":"[2023.06] On-Policy Distillation of Language Models: Learning from Self-Generated Mistakes GKD\u89e3\u51b3\u8bad\u63a8\u4e0d\u4e00\u81f4\u95ee\u9898\u3002","title":"1.4.1.6. \u84b8\u998f"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PostTraining/#142_reward_model","text":"[2025.04] Inference-Time Scaling for Generalist Reward Modeling / \u3010\u8bba\u6587\u89e3\u8bfb\u3011 SPCT \u8ba9\u6a21\u578b\u81ea\u5df1\u751f\u6210\u539f\u5219\uff0c\u7136\u540e\u751f\u6210\u6253\u5206\u3002 [2024.10] Generative Reward Models \u65af\u5766\u798f\uff0c\u5408\u6210\u5b9e\u9a8c\u5ba4\uff0cCoT-GenRM\uff0c\u5148\u901a\u8fc7prompt\u8ba9\u6a21\u578b\u7ed9Q\u751f\u6210\u63a8\u7406\u548cA\u6807\u8bb0\u51fa\u6b63\u786e\u7684\uff0c\u6216\u7ed9\u5b9aQ\u548cA\u751f\u6210\u63a8\u7406\u94fe\u3002\u7528\u5f97\u5230\u7684\u63a8\u7406\u6570\u636e\u505asft\u548cdpo\u3002\u5728\u96be\u5f97\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u66f4\u597d\u3002 [2024.08] Generative Verifiers: Reward Modeling as Next-Token Prediction \u8c37\u6b4c\uff0cdeepmind\uff0cCot-GenRM\uff0c\u53ea\u505a\u4e86sft [2024.06] HelpSteer2: Open-source dataset for training top-performing reward models nvidia/HelpSteer2 NVIDIA/NeMo-Aligner [2024.03] RewardBench: Evaluating Reward Models for Language Modeling allenai/reward-bench [2024.01] Secrets of RLHF in Large Language Models Part II: Reward Modeling \u590d\u65e6\u5927\u5b66\u90b1\u9521\u9e4f\u8001\u5e08\u6587\u7ae0\u89e3\u8bfb\uff1aSecrets of RLHF in Large Language Models Part II: Reward Modeling [2023.06] PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization WeOpenML/PandaLM","title":"1.4.2. Reward Model"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PostTraining/#15","text":"","title":"1.5. \u7ec6\u5206\u65b9\u5411"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PostTraining/#151","text":"[2025.04] Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning MiniF2F-test 80+% [2025.04] Leanabell-Prover: Posttraining Scaling in Formal Reasoning MiniF2F-test 59.8% [2024.08] DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search miniF2F-test\u8fbe\u523063.5% github:DeepSeek-Prover-V1.5","title":"1.5.1. \u5f62\u5f0f\u5316\u8bc1\u660e"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PostTraining/#152","text":"[2023.03] Rewarding Chatbots for Real-World Engagement with Millions of Users Chai\u7684\u8bba\u6587\uff0c\u7528RLHF\u4f18\u5316Chatbot","title":"1.5.2. \u89d2\u8272\u626e\u6f14"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PostTraining/#16","text":"LLM \u80fd\u4ece\u5355\u4e2a\u4f8b\u5b50\u4e2d\u5b66\u4e60\u5417\uff1f","title":"1.6. \u7406\u89e3\u5bf9\u9f50"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PreTraining/","text":"1. \u5927\u6a21\u578b\u5b66\u4e60\u8d44\u6599 # LLM\u5b66\u4e601\uff1a\u5927\u6a21\u578b\u67b6\u6784\u8981\u70b9\u603b\u7ed3 \u56de\u5fc6\u57fa\u7840\u77e5\u8bc6 github:llm-viz / \u7f51\u9875:bbycroft \u5927\u6a21\u578b\u7ed3\u6784\u53ef\u89c6\u5316 2. \u8bba\u6587\u548c\u5f00\u6e90\u5e93 # 2.1. DeepSeek # [2024.12] DeepSeek-V3 Technical Report / github:DeepSeek-V3 MLA\u3001MOE\u3001MTP\u3001GRPO\u7b49 [2024.05] DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model \u5de5\u4e1a\u754c\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u540e\u8bad\u7ec3(Post-Training)\u6280\u672f\u603b\u7ed3 [2024.01] DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models [2024.01] DeepSeek LLM: Scaling Open-Source Language Models with Longtermism 2.2. Google # [2025.03] Gemma 3 Technical Report \u591a\u6a21\u6001\u7406\u89e3\u3001\u84b8\u998f\u548c\u91cf\u5316 2.3. Openai # [2024.03] GPT-4 Technical Report 2.4. \u667a\u8c31AI # [2024.07] ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools GLM-4 3. \u5927\u6a21\u578b\u9884\u8bad\u7ec3\u6838\u5fc3\u6a21\u5757 # 3.1. \u6570\u636e\u9884\u5904\u7406 # \u6570\u636e\u6e05\u6d17 kenlm \u901f\u5ea6\u5feb\uff0c\u5360\u7528\u5185\u5b58\u5c0f\uff0c\u652f\u6301\u591a\u7ebf\u7a0b\u3002\u7528\u4f18\u8d28\u8bed\u6599\u8bad\u7ec3\u6a21\u578b\uff0c\u7136\u540e\u7528\u6765\u8fc7\u6ee4\u4f4e\u8d28\u91cf\u8bed\u6599\u3002 \u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e4b\u6570\u636e\u5e73\u6ed1\u65b9\u6cd5 \u7b2c\u4e00\u79cd\u7c7b\u578b\u4e3a\u653f\u5e9c\u7ed9\u5927\u5bb6\u6bcf\u4eba\u4e00\u7b14\u6216\u8005\u51e0\u7b14\u94b1\uff08\u59821\u548c2\uff09\uff0c\u7b2c\u4e8c\u79cd\u4e3a\u627e\u7236\u6bcd\u8981\uff08\u59823\u548c4\uff09\uff0c\u6700\u540e\u4e00\u79cd\u5c31\u662f\u52ab\u5bcc\u6d4e\u8d2b\uff08\u59825-7\uff09\u3002\u6bd4\u55bb\u5f88\u597d\uff0c\u6700\u540ekn\u5e73\u6ed1\u7684\u516c\u5f0f\u56fe\u4e0d\u5bf9\u3002 Kenlm\u4e2d\u4f7f\u7528\u7684Modified Kneser-Ney \u5e73\u6ed1\u65b9\u6cd5\u548c\u8ba1\u7b97\u8fc7\u7a0b\u63a8\u6f14 \u628akn\u7684\u516c\u5f0f\u63a8\u6f14\u4e86\u4e00\u904d\uff0c\u8ddf\u4e0a\u9762\u6587\u7ae0\u7684\u7ed3\u5408\u770b\u4f1a\u6bd4\u8f83\u597d\u7406\u89e3\u3002 github:kenlm kenlm\u7684c++\u5b9e\u73b0,\u5b98\u65b9\u5e93 github:kneser-ney kn\u7684python\u5b9e\u73b0 Scalable Modified Kneser-Ney Language Model Estimation \u6bd4srilm\u75287.7%\u7684ram\u548c14%\u7684\u65f6\u95f4\u3002\u4ecb\u7ecd\u4e86kn\u7684\u4f18\u5316\u3002 KenLM: Faster and Smaller Language Model Queries \u4ecb\u7ecd\u4e86kenlm\u7684\u4f18\u5316\u3002trie\u6570\u5b58\u50a8n-gram\u6982\u7387\u964d\u5e8f\u6392\u5217\uff0cbit-level\u538b\u7f29\u5b58\u50a8\u6982\u7387\u548cbackoff\uff0c\u53d8\u957f\u7f16\u7801\u5b58\u50a8n-gram\u7d22\u5f15\u3002\u4e0e\u8ba1\u7b97\u8fb9\u754c\u6761\u4ef6\u6982\u7387\u3001\u7528sse\u6307\u4ee4\u5e76\u884c\u8ba1\u7b97\u3001\u5ef6\u8fdfbackoff\u8ba1\u7b97\u3002mmio\u5b9e\u73b0\u96f6\u62f7\u8d1d\u52a0\u8f7d\u3002 \u6570\u636e\u53bb\u91cd \u6587\u672c\u6807\u51c6\u5316\uff08\u5927\u5c0f\u5199\u3001\u6807\u70b9\u7b49\uff09 \u6570\u636e\u589e\u5f3a [2024.04] Fewer Truncations Improve Language Modeling [2022.07] Efficient Training of Language Models to Fill in the Middle 3.2. Tokenization # \u4ecb\u7ecd\u548c\u4ee3\u7801\u5e93\uff1a \u5927\u6a21\u578b\u57fa\u7840\u7ec4\u4ef6 - Tokenizer \u8be6\u7ec6\u4ecb\u7ecd\u4e86bpe\u3001bbpe\u3001wordpiece\u3001sentencepiece huggingface/tokenizers \u7b97\u6cd5\uff1a byte-pair-encoding (BPE) [2016] Neural Machine Translation of Rare Words with Subword Units bpe\u7528subword\u6765\u5904\u7406oov\u95ee\u9898\u3002\u628a\u8bcd\u6253\u6563\u6210char\uff0c\u8bcd\u5c3e\u9700\u8981\u6dfb\u52a0\u7279\u6b8a\u5b57\u7b26<\\w>\u3002 \u901a\u8fc7\u5408\u5e76\u6700\u9891\u7e41\u51fa\u73b0\u7684\u76f8\u90bb\u5b50\u8bcd\u5bf9\u6765\u8fed\u4ee3\u5730\u6784\u5efa\u66f4\u5927\u7684\u5b50\u8bcd\u5355\u5143\u3002 github:subword-nmt WordPiece [2016.10] Google\u2019s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation \u57fa\u4e8elstm\u76848\u5c42encoder-decoder\u6a21\u578b\u5904\u7406\u7ffb\u8bd1\u4efb\u52a1,\u7528\u5230\u4e86\u6b8b\u5dee\u3002\u63d0\u51fa\u4e86wordpiece, \u5728\u8bcd\u9996\u6dfb\u52a0_\u8bcd\u9996\u7b26\u53f7\u3002\u901a\u8fc7\u6982\u7387\u6700\u5927\u5316\u9009\u62e9\u5b50\u8bcd\u5bf9\u3002 BBPE [2019.09] Neural Machine Translation with Byte-Level Subwords SentencePiece github:google/sentencepiece NFKC-based normalization, [2018.08] SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing [2018.04] Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates \u6bcf\u6b21\u8bad\u7ec3\u65f6\u4ece\u6982\u7387\u5206\u5e03\u4e2d\u968f\u673a\u91c7\u6837\u4e00\u79cd\u5206\u5272\u65b9\u5f0f\u4f5c\u4e3a\u8f93\u5165\uff0c\u800c\u975e\u56fa\u5b9a\u4f7f\u7528\u6700\u9ad8\u6982\u7387\u5206\u5272\u3002 [2019.10] BPE-Dropout: Simple and Effective Subword Regularization \u4ee5\u6982\u7387 p \u968f\u673a\u8df3\u8fc7\u67d0\u4e9b\u5408\u5e76\u6b65\u9aa4\u3002 3.3. \u6a21\u578b\u67b6\u6784 # Transformer\u7ed3\u6784\u9009\u62e9\uff08Encoder/Decoder/Encoder-Decoder\uff09 \u4f4d\u7f6e\u7f16\u7801\u65b9\u6848\uff08\u7edd\u5bf9/\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\uff09 rope [2021.03] Transformer\u5347\u7ea7\u4e4b\u8def\uff1a2\u3001\u535a\u91c7\u4f17\u957f\u7684\u65cb\u8f6c\u5f0f\u4f4d\u7f6e\u7f16\u7801 \u6bcf2\u4f4d\u505a\u4e00\u4e2a\u65cb\u8f6c\uff0c\u65cb\u8f6c\u89d2\u5ea6\u4e3a1/2^k, \u5176\u4e2dk\u4e3a\u4f4d\u7f6e\u3002qk\u76f8\u4e58\u4e4b\u540e\u76f8\u5bf9\u8ddd\u79bb\u8d8a\u8fdc\uff0cqk\u7684\u4e58\u79ef\u8d8a\u5c0f\u3002 \u65cb\u8f6c\u77e9\u9635\u53ca\u5de6\u53f3\u4e58\u7684\u610f\u4e49\uff0c\u770b\u8fd9\u4e00\u7bc7\u5c31\u591f\u4e86 \u5f52\u4e00\u5316\u5c42\u9009\u62e9\uff08LayerNorm/RMSNorm\uff09 LayerNorm VS BatchNorm VS RMSNorm Group Normalization \u8fd9\u91cc\u662f\u56fe\u50cf\u4e2d\u7684norm\uff0c\u8ddfnlp\u4e2d\u7684\u8fd8\u4e0d\u592a\u4e00\u6837 [2019.10] Root Mean Square Layer Normalization RMSNorm\u6027\u80fd\u548cLayerNorm\u76f8\u5f53\uff0c\u4f46\u662f\u53ef\u4ee5\u8282\u77017%\u523064%\u7684\u8fd0\u7b97\u3002 \u6fc0\u6d3b\u51fd\u6570 \u6fc0\u6d3b\u51fd\u6570 Relu,Gelu,Mish,SiLU,Swish,Tanh,Sigmoid deepseek\u4f7f\u7528silu\uff0cSiLU\u5177\u5907\u65e0\u4e0a\u754c\u6709\u4e0b\u754c\u3001\u5e73\u6ed1\u3001\u975e\u5355\u8c03\u7684\u7279\u6027\u3002SiLU\u5728\u6df1\u5c42\u6a21\u578b\u4e0a\u7684\u6548\u679c\u4f18\u4e8e ReLU\u3002\u53ef\u4ee5\u770b\u505a\u662f\u5e73\u6ed1\u7684ReLU\u6fc0\u6d3b\u51fd\u6570\u3002 \u957f\u4e0a\u4e0b\u6587 [2023.08] YaRN: Efficient Context Window Extension of Large Language Models \u8bba\u6587YaRN: Efficient Context Window Extension of Large Language Models\u7b14\u8bb0 \u6fc0\u6d3b\u51fd\u6570 # [2020.02] GLU Variants Improve Transformer SwiGLU\u3002\u8bba\u6587\u63d0\u5230\u9884\u8bad\u7ec3\u4e0d\u7528dropout\u6548\u679c\u66f4\u597d\u3002GLU\u6548\u679c\u66f4\u597d\uff0c\u4f5c\u8005\u89e3\u91ca\u4e0d\u4e86\uff0c\u6240\u4ee5\u5f52\u56e0\u4e8e\u4e0a\u5929\u7737\u987e [2017.10] Searching for Activation Functions [2016.06] Gaussian Error Linear Units (GELUs) 3.4. \u6ce8\u610f\u529b\u673a\u5236 # \u7f13\u5b58\u4e0e\u6548\u679c\u7684\u6781\u9650\u62c9\u626f\uff1a\u4eceMHA\u3001MQA\u3001GQA\u5230MLA \u8282\u7ea6kv cache\u7a7a\u95f4\u3002 [2024.01] Lightning Attention-2: A Free Lunch for Handling Unlimited Sequence Lengths in Large Language Models OpenNLPLab/lightning-attention \u65b0\u4e00\u4ee3\u6ce8\u610f\u529b\u673a\u5236Lightning Attention-2\uff1a\u65e0\u9650\u5e8f\u5217\u957f\u5ea6\u3001\u6052\u5b9a\u7b97\u529b\u5f00\u9500\u3001\u66f4\u9ad8\u5efa\u6a21\u7cbe\u5ea6 [2023.07] TransNormerLLM: A Faster and Better Large Language Model with Improved TransNormer [2020.01] Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention \u7ebf\u6027\u6ce8\u610f\u529b \u7ebf\u6027Attention\u7684\u63a2\u7d22\uff1aAttention\u5fc5\u987b\u6709\u4e2aSoftmax\u5417\uff1f \u7b14\u8bb0\uff1a\u7b80\u5355\u56fe\u89e3\u4e00\u4e0b\u7ebf\u6027\u6ce8\u610f\u529b\u673a\u5236 SSM(State Space Model) \u5b9e\u73b0\u4e86\u5bf9\u6bcf\u4e00\u4e2a\u5386\u53f2\u6b65\u9aa4\u7684\u8bb0\u5f55\u548c\u538b\u7f29\uff0c\u4f46\u662f\u5ffd\u7565\u4e86\u5177\u4f53\u7684\u6b65\u6570\u7d22\u5f15\u3002 [2019.04] Generating Long Sequences with Sparse Transformers \u7a00\u758f\u6ce8\u610f\u529b openai/sparse_attention \u4e3a\u8282\u7ea6\u800c\u751f\uff1a\u4ece\u6807\u51c6Attention\u5230\u7a00\u758fAttention Transformer\u7efc\u8ff0\uff08\u4e00\uff09\uff1a\u7a00\u758f\u6ce8\u610f\u529b Sliding Window Attention\uff08\u6ed1\u52a8\u7a97\u53e3\u6ce8\u610f\u529b\uff09 [2023.09] Mistral 7B 3.5. \u8bad\u7ec3\u7b56\u7565 # \u4f18\u5316\u5668\u9009\u62e9\uff08Adam/AdamW/LAMB\uff09 \u5b66\u4e60\u7387\u8c03\u5ea6\uff08\u7ebf\u6027\u9884\u70ed+\u4f59\u5f26\u8870\u51cf\uff09 \u6279\u6b21\u7b56\u7565\uff08\u52a8\u6001\u6279\u5904\u7406/\u68af\u5ea6\u7d2f\u79ef\uff09 \u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\uff08FP16/BF16\uff09 3.6. \u5206\u5e03\u5f0f\u8bad\u7ec3 # huggingface: Model Parallelism \u6570\u636e\u5e76\u884c\uff08Data Parallelism\uff09 \u6d41\u6c34\u7ebf\u5e76\u884c\uff08Pipeline Parallelism\uff09 \u5f20\u91cf\u5e76\u884c\uff08Tensor Parallelism\uff09 3D\u5e76\u884c\u7b56\u7565\u7ec4\u5408 3.7. \u635f\u5931\u51fd\u6570 # \u8bed\u8a00\u5efa\u6a21\u635f\u5931\uff08\u6807\u51c6\u4ea4\u53c9\u71b5\uff09 \u63a9\u7801\u8bed\u8a00\u5efa\u6a21\uff08MLM\uff09 \u5e8f\u5217\u5230\u5e8f\u5217\u635f\u5931 \u7279\u6b8atoken\u5904\u7406\u7b56\u7565 3.8. \u76d1\u63a7\u4e0e\u8c03\u8bd5 # \u8bad\u7ec3\u52a8\u6001\u76d1\u63a7\uff08\u635f\u5931/\u68af\u5ea6/\u6fc0\u6d3b\u503c\uff09 \u663e\u5b58\u4f7f\u7528\u5206\u6790 \u5f02\u5e38\u68c0\u6d4b\uff08\u68af\u5ea6\u7206\u70b8/\u6d88\u5931\uff09 \u6a21\u578b\u68c0\u67e5\u70b9\u7ba1\u7406 3.9. \u6269\u5c55\u6280\u672f # \u8bfe\u7a0b\u5b66\u4e60\uff08Curriculum Learning\uff09 \u6a21\u578b\u589e\u957f\uff08\u6e10\u8fdb\u5f0f\u8bad\u7ec3\uff09 \u77e5\u8bc6\u84b8\u998f\uff08Teacher-Student\uff09 \u6301\u7eed\u9884\u8bad\u7ec3","title":"PreTraining"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PreTraining/#1","text":"LLM\u5b66\u4e601\uff1a\u5927\u6a21\u578b\u67b6\u6784\u8981\u70b9\u603b\u7ed3 \u56de\u5fc6\u57fa\u7840\u77e5\u8bc6 github:llm-viz / \u7f51\u9875:bbycroft \u5927\u6a21\u578b\u7ed3\u6784\u53ef\u89c6\u5316","title":"1. \u5927\u6a21\u578b\u5b66\u4e60\u8d44\u6599"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PreTraining/#2","text":"","title":"2. \u8bba\u6587\u548c\u5f00\u6e90\u5e93"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PreTraining/#21_deepseek","text":"[2024.12] DeepSeek-V3 Technical Report / github:DeepSeek-V3 MLA\u3001MOE\u3001MTP\u3001GRPO\u7b49 [2024.05] DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model \u5de5\u4e1a\u754c\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u540e\u8bad\u7ec3(Post-Training)\u6280\u672f\u603b\u7ed3 [2024.01] DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models [2024.01] DeepSeek LLM: Scaling Open-Source Language Models with Longtermism","title":"2.1. DeepSeek"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PreTraining/#22_google","text":"[2025.03] Gemma 3 Technical Report \u591a\u6a21\u6001\u7406\u89e3\u3001\u84b8\u998f\u548c\u91cf\u5316","title":"2.2. Google"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PreTraining/#23_openai","text":"[2024.03] GPT-4 Technical Report","title":"2.3. Openai"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PreTraining/#24_ai","text":"[2024.07] ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools GLM-4","title":"2.4. \u667a\u8c31AI"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PreTraining/#3","text":"","title":"3. \u5927\u6a21\u578b\u9884\u8bad\u7ec3\u6838\u5fc3\u6a21\u5757"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PreTraining/#31","text":"\u6570\u636e\u6e05\u6d17 kenlm \u901f\u5ea6\u5feb\uff0c\u5360\u7528\u5185\u5b58\u5c0f\uff0c\u652f\u6301\u591a\u7ebf\u7a0b\u3002\u7528\u4f18\u8d28\u8bed\u6599\u8bad\u7ec3\u6a21\u578b\uff0c\u7136\u540e\u7528\u6765\u8fc7\u6ee4\u4f4e\u8d28\u91cf\u8bed\u6599\u3002 \u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e4b\u6570\u636e\u5e73\u6ed1\u65b9\u6cd5 \u7b2c\u4e00\u79cd\u7c7b\u578b\u4e3a\u653f\u5e9c\u7ed9\u5927\u5bb6\u6bcf\u4eba\u4e00\u7b14\u6216\u8005\u51e0\u7b14\u94b1\uff08\u59821\u548c2\uff09\uff0c\u7b2c\u4e8c\u79cd\u4e3a\u627e\u7236\u6bcd\u8981\uff08\u59823\u548c4\uff09\uff0c\u6700\u540e\u4e00\u79cd\u5c31\u662f\u52ab\u5bcc\u6d4e\u8d2b\uff08\u59825-7\uff09\u3002\u6bd4\u55bb\u5f88\u597d\uff0c\u6700\u540ekn\u5e73\u6ed1\u7684\u516c\u5f0f\u56fe\u4e0d\u5bf9\u3002 Kenlm\u4e2d\u4f7f\u7528\u7684Modified Kneser-Ney \u5e73\u6ed1\u65b9\u6cd5\u548c\u8ba1\u7b97\u8fc7\u7a0b\u63a8\u6f14 \u628akn\u7684\u516c\u5f0f\u63a8\u6f14\u4e86\u4e00\u904d\uff0c\u8ddf\u4e0a\u9762\u6587\u7ae0\u7684\u7ed3\u5408\u770b\u4f1a\u6bd4\u8f83\u597d\u7406\u89e3\u3002 github:kenlm kenlm\u7684c++\u5b9e\u73b0,\u5b98\u65b9\u5e93 github:kneser-ney kn\u7684python\u5b9e\u73b0 Scalable Modified Kneser-Ney Language Model Estimation \u6bd4srilm\u75287.7%\u7684ram\u548c14%\u7684\u65f6\u95f4\u3002\u4ecb\u7ecd\u4e86kn\u7684\u4f18\u5316\u3002 KenLM: Faster and Smaller Language Model Queries \u4ecb\u7ecd\u4e86kenlm\u7684\u4f18\u5316\u3002trie\u6570\u5b58\u50a8n-gram\u6982\u7387\u964d\u5e8f\u6392\u5217\uff0cbit-level\u538b\u7f29\u5b58\u50a8\u6982\u7387\u548cbackoff\uff0c\u53d8\u957f\u7f16\u7801\u5b58\u50a8n-gram\u7d22\u5f15\u3002\u4e0e\u8ba1\u7b97\u8fb9\u754c\u6761\u4ef6\u6982\u7387\u3001\u7528sse\u6307\u4ee4\u5e76\u884c\u8ba1\u7b97\u3001\u5ef6\u8fdfbackoff\u8ba1\u7b97\u3002mmio\u5b9e\u73b0\u96f6\u62f7\u8d1d\u52a0\u8f7d\u3002 \u6570\u636e\u53bb\u91cd \u6587\u672c\u6807\u51c6\u5316\uff08\u5927\u5c0f\u5199\u3001\u6807\u70b9\u7b49\uff09 \u6570\u636e\u589e\u5f3a [2024.04] Fewer Truncations Improve Language Modeling [2022.07] Efficient Training of Language Models to Fill in the Middle","title":"3.1. \u6570\u636e\u9884\u5904\u7406"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PreTraining/#32_tokenization","text":"\u4ecb\u7ecd\u548c\u4ee3\u7801\u5e93\uff1a \u5927\u6a21\u578b\u57fa\u7840\u7ec4\u4ef6 - Tokenizer \u8be6\u7ec6\u4ecb\u7ecd\u4e86bpe\u3001bbpe\u3001wordpiece\u3001sentencepiece huggingface/tokenizers \u7b97\u6cd5\uff1a byte-pair-encoding (BPE) [2016] Neural Machine Translation of Rare Words with Subword Units bpe\u7528subword\u6765\u5904\u7406oov\u95ee\u9898\u3002\u628a\u8bcd\u6253\u6563\u6210char\uff0c\u8bcd\u5c3e\u9700\u8981\u6dfb\u52a0\u7279\u6b8a\u5b57\u7b26<\\w>\u3002 \u901a\u8fc7\u5408\u5e76\u6700\u9891\u7e41\u51fa\u73b0\u7684\u76f8\u90bb\u5b50\u8bcd\u5bf9\u6765\u8fed\u4ee3\u5730\u6784\u5efa\u66f4\u5927\u7684\u5b50\u8bcd\u5355\u5143\u3002 github:subword-nmt WordPiece [2016.10] Google\u2019s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation \u57fa\u4e8elstm\u76848\u5c42encoder-decoder\u6a21\u578b\u5904\u7406\u7ffb\u8bd1\u4efb\u52a1,\u7528\u5230\u4e86\u6b8b\u5dee\u3002\u63d0\u51fa\u4e86wordpiece, \u5728\u8bcd\u9996\u6dfb\u52a0_\u8bcd\u9996\u7b26\u53f7\u3002\u901a\u8fc7\u6982\u7387\u6700\u5927\u5316\u9009\u62e9\u5b50\u8bcd\u5bf9\u3002 BBPE [2019.09] Neural Machine Translation with Byte-Level Subwords SentencePiece github:google/sentencepiece NFKC-based normalization, [2018.08] SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing [2018.04] Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates \u6bcf\u6b21\u8bad\u7ec3\u65f6\u4ece\u6982\u7387\u5206\u5e03\u4e2d\u968f\u673a\u91c7\u6837\u4e00\u79cd\u5206\u5272\u65b9\u5f0f\u4f5c\u4e3a\u8f93\u5165\uff0c\u800c\u975e\u56fa\u5b9a\u4f7f\u7528\u6700\u9ad8\u6982\u7387\u5206\u5272\u3002 [2019.10] BPE-Dropout: Simple and Effective Subword Regularization \u4ee5\u6982\u7387 p \u968f\u673a\u8df3\u8fc7\u67d0\u4e9b\u5408\u5e76\u6b65\u9aa4\u3002","title":"3.2. Tokenization"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PreTraining/#33","text":"Transformer\u7ed3\u6784\u9009\u62e9\uff08Encoder/Decoder/Encoder-Decoder\uff09 \u4f4d\u7f6e\u7f16\u7801\u65b9\u6848\uff08\u7edd\u5bf9/\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\uff09 rope [2021.03] Transformer\u5347\u7ea7\u4e4b\u8def\uff1a2\u3001\u535a\u91c7\u4f17\u957f\u7684\u65cb\u8f6c\u5f0f\u4f4d\u7f6e\u7f16\u7801 \u6bcf2\u4f4d\u505a\u4e00\u4e2a\u65cb\u8f6c\uff0c\u65cb\u8f6c\u89d2\u5ea6\u4e3a1/2^k, \u5176\u4e2dk\u4e3a\u4f4d\u7f6e\u3002qk\u76f8\u4e58\u4e4b\u540e\u76f8\u5bf9\u8ddd\u79bb\u8d8a\u8fdc\uff0cqk\u7684\u4e58\u79ef\u8d8a\u5c0f\u3002 \u65cb\u8f6c\u77e9\u9635\u53ca\u5de6\u53f3\u4e58\u7684\u610f\u4e49\uff0c\u770b\u8fd9\u4e00\u7bc7\u5c31\u591f\u4e86 \u5f52\u4e00\u5316\u5c42\u9009\u62e9\uff08LayerNorm/RMSNorm\uff09 LayerNorm VS BatchNorm VS RMSNorm Group Normalization \u8fd9\u91cc\u662f\u56fe\u50cf\u4e2d\u7684norm\uff0c\u8ddfnlp\u4e2d\u7684\u8fd8\u4e0d\u592a\u4e00\u6837 [2019.10] Root Mean Square Layer Normalization RMSNorm\u6027\u80fd\u548cLayerNorm\u76f8\u5f53\uff0c\u4f46\u662f\u53ef\u4ee5\u8282\u77017%\u523064%\u7684\u8fd0\u7b97\u3002 \u6fc0\u6d3b\u51fd\u6570 \u6fc0\u6d3b\u51fd\u6570 Relu,Gelu,Mish,SiLU,Swish,Tanh,Sigmoid deepseek\u4f7f\u7528silu\uff0cSiLU\u5177\u5907\u65e0\u4e0a\u754c\u6709\u4e0b\u754c\u3001\u5e73\u6ed1\u3001\u975e\u5355\u8c03\u7684\u7279\u6027\u3002SiLU\u5728\u6df1\u5c42\u6a21\u578b\u4e0a\u7684\u6548\u679c\u4f18\u4e8e ReLU\u3002\u53ef\u4ee5\u770b\u505a\u662f\u5e73\u6ed1\u7684ReLU\u6fc0\u6d3b\u51fd\u6570\u3002 \u957f\u4e0a\u4e0b\u6587 [2023.08] YaRN: Efficient Context Window Extension of Large Language Models \u8bba\u6587YaRN: Efficient Context Window Extension of Large Language Models\u7b14\u8bb0","title":"3.3. \u6a21\u578b\u67b6\u6784"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PreTraining/#_1","text":"[2020.02] GLU Variants Improve Transformer SwiGLU\u3002\u8bba\u6587\u63d0\u5230\u9884\u8bad\u7ec3\u4e0d\u7528dropout\u6548\u679c\u66f4\u597d\u3002GLU\u6548\u679c\u66f4\u597d\uff0c\u4f5c\u8005\u89e3\u91ca\u4e0d\u4e86\uff0c\u6240\u4ee5\u5f52\u56e0\u4e8e\u4e0a\u5929\u7737\u987e [2017.10] Searching for Activation Functions [2016.06] Gaussian Error Linear Units (GELUs)","title":"\u6fc0\u6d3b\u51fd\u6570"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PreTraining/#34","text":"\u7f13\u5b58\u4e0e\u6548\u679c\u7684\u6781\u9650\u62c9\u626f\uff1a\u4eceMHA\u3001MQA\u3001GQA\u5230MLA \u8282\u7ea6kv cache\u7a7a\u95f4\u3002 [2024.01] Lightning Attention-2: A Free Lunch for Handling Unlimited Sequence Lengths in Large Language Models OpenNLPLab/lightning-attention \u65b0\u4e00\u4ee3\u6ce8\u610f\u529b\u673a\u5236Lightning Attention-2\uff1a\u65e0\u9650\u5e8f\u5217\u957f\u5ea6\u3001\u6052\u5b9a\u7b97\u529b\u5f00\u9500\u3001\u66f4\u9ad8\u5efa\u6a21\u7cbe\u5ea6 [2023.07] TransNormerLLM: A Faster and Better Large Language Model with Improved TransNormer [2020.01] Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention \u7ebf\u6027\u6ce8\u610f\u529b \u7ebf\u6027Attention\u7684\u63a2\u7d22\uff1aAttention\u5fc5\u987b\u6709\u4e2aSoftmax\u5417\uff1f \u7b14\u8bb0\uff1a\u7b80\u5355\u56fe\u89e3\u4e00\u4e0b\u7ebf\u6027\u6ce8\u610f\u529b\u673a\u5236 SSM(State Space Model) \u5b9e\u73b0\u4e86\u5bf9\u6bcf\u4e00\u4e2a\u5386\u53f2\u6b65\u9aa4\u7684\u8bb0\u5f55\u548c\u538b\u7f29\uff0c\u4f46\u662f\u5ffd\u7565\u4e86\u5177\u4f53\u7684\u6b65\u6570\u7d22\u5f15\u3002 [2019.04] Generating Long Sequences with Sparse Transformers \u7a00\u758f\u6ce8\u610f\u529b openai/sparse_attention \u4e3a\u8282\u7ea6\u800c\u751f\uff1a\u4ece\u6807\u51c6Attention\u5230\u7a00\u758fAttention Transformer\u7efc\u8ff0\uff08\u4e00\uff09\uff1a\u7a00\u758f\u6ce8\u610f\u529b Sliding Window Attention\uff08\u6ed1\u52a8\u7a97\u53e3\u6ce8\u610f\u529b\uff09 [2023.09] Mistral 7B","title":"3.4. \u6ce8\u610f\u529b\u673a\u5236"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PreTraining/#35","text":"\u4f18\u5316\u5668\u9009\u62e9\uff08Adam/AdamW/LAMB\uff09 \u5b66\u4e60\u7387\u8c03\u5ea6\uff08\u7ebf\u6027\u9884\u70ed+\u4f59\u5f26\u8870\u51cf\uff09 \u6279\u6b21\u7b56\u7565\uff08\u52a8\u6001\u6279\u5904\u7406/\u68af\u5ea6\u7d2f\u79ef\uff09 \u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\uff08FP16/BF16\uff09","title":"3.5. \u8bad\u7ec3\u7b56\u7565"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PreTraining/#36","text":"huggingface: Model Parallelism \u6570\u636e\u5e76\u884c\uff08Data Parallelism\uff09 \u6d41\u6c34\u7ebf\u5e76\u884c\uff08Pipeline Parallelism\uff09 \u5f20\u91cf\u5e76\u884c\uff08Tensor Parallelism\uff09 3D\u5e76\u884c\u7b56\u7565\u7ec4\u5408","title":"3.6. \u5206\u5e03\u5f0f\u8bad\u7ec3"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PreTraining/#37","text":"\u8bed\u8a00\u5efa\u6a21\u635f\u5931\uff08\u6807\u51c6\u4ea4\u53c9\u71b5\uff09 \u63a9\u7801\u8bed\u8a00\u5efa\u6a21\uff08MLM\uff09 \u5e8f\u5217\u5230\u5e8f\u5217\u635f\u5931 \u7279\u6b8atoken\u5904\u7406\u7b56\u7565","title":"3.7. \u635f\u5931\u51fd\u6570"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PreTraining/#38","text":"\u8bad\u7ec3\u52a8\u6001\u76d1\u63a7\uff08\u635f\u5931/\u68af\u5ea6/\u6fc0\u6d3b\u503c\uff09 \u663e\u5b58\u4f7f\u7528\u5206\u6790 \u5f02\u5e38\u68c0\u6d4b\uff08\u68af\u5ea6\u7206\u70b8/\u6d88\u5931\uff09 \u6a21\u578b\u68c0\u67e5\u70b9\u7ba1\u7406","title":"3.8. \u76d1\u63a7\u4e0e\u8c03\u8bd5"},{"location":"4.%5B%E6%A8%A1%E5%9E%8B%5D%E6%96%87%E6%9C%AC/PreTraining/#39","text":"\u8bfe\u7a0b\u5b66\u4e60\uff08Curriculum Learning\uff09 \u6a21\u578b\u589e\u957f\uff08\u6e10\u8fdb\u5f0f\u8bad\u7ec3\uff09 \u77e5\u8bc6\u84b8\u998f\uff08Teacher-Student\uff09 \u6301\u7eed\u9884\u8bad\u7ec3","title":"3.9. \u6269\u5c55\u6280\u672f"},{"location":"5.%5B%E6%A8%A1%E5%9E%8B%5D%E5%A4%9A%E6%A8%A1%E6%80%81/MultiModalEmbedding/","text":"\u591a\u6a21\u6001Embedding # \u5f00\u6e90\u8d44\u6e90 # VGG [2014.09] Very Deep Convolutional Networks for Large-Scale Image Recognition https://pytorch.org/vision/stable/models/vgg.html CLIP [2021.02] Learning Transferable Visual Models From Natural Language Supervision \u6587\u672c\u56fe\u7247\u5bf9\u6bd4\u8bad\u7ec3\uff0c","title":"MultiModalEmbedding"},{"location":"5.%5B%E6%A8%A1%E5%9E%8B%5D%E5%A4%9A%E6%A8%A1%E6%80%81/MultiModalEmbedding/#embedding","text":"","title":"\u591a\u6a21\u6001Embedding"},{"location":"5.%5B%E6%A8%A1%E5%9E%8B%5D%E5%A4%9A%E6%A8%A1%E6%80%81/MultiModalEmbedding/#_1","text":"VGG [2014.09] Very Deep Convolutional Networks for Large-Scale Image Recognition https://pytorch.org/vision/stable/models/vgg.html CLIP [2021.02] Learning Transferable Visual Models From Natural Language Supervision \u6587\u672c\u56fe\u7247\u5bf9\u6bd4\u8bad\u7ec3\uff0c","title":"\u5f00\u6e90\u8d44\u6e90"},{"location":"5.%5B%E6%A8%A1%E5%9E%8B%5D%E5%A4%9A%E6%A8%A1%E6%80%81/T2V/","text":"\u6587\u7ae0 # [2023.05] Training Diffusion Models with Reinforcement Learning \u7528VLM+RL\u8bad\u7ec3Diffusion\u6a21\u578b jannerm/ddpo [2025.05] DanceGRPO: Unleashing GRPO on Visual Generation","title":"T2V"},{"location":"5.%5B%E6%A8%A1%E5%9E%8B%5D%E5%A4%9A%E6%A8%A1%E6%80%81/T2V/#_1","text":"[2023.05] Training Diffusion Models with Reinforcement Learning \u7528VLM+RL\u8bad\u7ec3Diffusion\u6a21\u578b jannerm/ddpo [2025.05] DanceGRPO: Unleashing GRPO on Visual Generation","title":"\u6587\u7ae0"},{"location":"5.%5B%E6%A8%A1%E5%9E%8B%5D%E5%A4%9A%E6%A8%A1%E6%80%81/VLA/","text":"VLA # \u5f00\u6e90\u5de5\u4f5c # [2025.06] AutoVLA: A Vision-Language-Action Model for End-to-End Autonomous Driving with Adaptive Reasoning and Reinforcement Fine-Tuning [2025.06] Unified Vision-Language-Action Model [2025.05] Vision-Language-Action Models: Concepts, Progress, Applications and Challenges [2025.03] CoT-VLA: Visual Chain-of-Thought Reasoning for Vision-Language-Action Models https://cot-vla.github.io/ [2024.06] OpenVLA: An Open-Source Vision-Language-Action Model https://github.com/openvla/openvla [2024.03] Octo: An Open-Source Generalist Robot Policy https://octo-models.github.io/ [2023.07] RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control [2023.03] PaLM-E: An Embodied Multimodal Language Model [2023.03] Diffusion Policy: Visuomotor Policy Learning via Action Diffusion [2022.12] RT-1: Robotics Transformer for Real-World Control at Scale [2022.08] Do As I Can, Not As I Say:Grounding Language in Robotic Affordances https://say-can.github.io/ [2022.05] Gato: A Generalist Agent \u6570\u636e\u96c6 # [2023.10] Open X-Embodiment: Robotic Learning Datasets and RT-X Models https://robotics-transformer-x.github.io/","title":"VLA"},{"location":"5.%5B%E6%A8%A1%E5%9E%8B%5D%E5%A4%9A%E6%A8%A1%E6%80%81/VLA/#vla","text":"","title":"VLA"},{"location":"5.%5B%E6%A8%A1%E5%9E%8B%5D%E5%A4%9A%E6%A8%A1%E6%80%81/VLA/#_1","text":"[2025.06] AutoVLA: A Vision-Language-Action Model for End-to-End Autonomous Driving with Adaptive Reasoning and Reinforcement Fine-Tuning [2025.06] Unified Vision-Language-Action Model [2025.05] Vision-Language-Action Models: Concepts, Progress, Applications and Challenges [2025.03] CoT-VLA: Visual Chain-of-Thought Reasoning for Vision-Language-Action Models https://cot-vla.github.io/ [2024.06] OpenVLA: An Open-Source Vision-Language-Action Model https://github.com/openvla/openvla [2024.03] Octo: An Open-Source Generalist Robot Policy https://octo-models.github.io/ [2023.07] RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control [2023.03] PaLM-E: An Embodied Multimodal Language Model [2023.03] Diffusion Policy: Visuomotor Policy Learning via Action Diffusion [2022.12] RT-1: Robotics Transformer for Real-World Control at Scale [2022.08] Do As I Can, Not As I Say:Grounding Language in Robotic Affordances https://say-can.github.io/ [2022.05] Gato: A Generalist Agent","title":"\u5f00\u6e90\u5de5\u4f5c"},{"location":"5.%5B%E6%A8%A1%E5%9E%8B%5D%E5%A4%9A%E6%A8%A1%E6%80%81/VLA/#_2","text":"[2023.10] Open X-Embodiment: Robotic Learning Datasets and RT-X Models https://robotics-transformer-x.github.io/","title":"\u6570\u636e\u96c6"},{"location":"5.%5B%E6%A8%A1%E5%9E%8B%5D%E5%A4%9A%E6%A8%A1%E6%80%81/VLM/","text":"\u591a\u6a21\u6001\u5927\u6a21\u578b # \u5b66\u4e60\u8d44\u6599 # \u5f00\u6e90\u9879\u76ee # [2025.04] Kimi-VL Technical Report MoonshotAI/Kimi-VL [2025.01] MiniMax-01: Scaling Foundation Models with Lightning Attention MiniMax-AI/MiniMax-01 [2024.03] VisionLLaMA: A Unified LLaMA Backbone for Vision Tasks RoPE-2D\u7684\u5f15\u5165\u6709\u52a9\u4e8e\u63d0\u5347\u6a21\u578b\u6548\u679c\u5c24\u5176\u662f\u53d8\u5206\u8fa8\u7387\u8f93\u5165\u7684\u6548\u679c Meituan-AutoML/VisionLLaMA minimind-v \u6781\u7b80vlm\u6a21\u578b LLaVA [2023.10] Improved Baselines with Visual Instruction Tuning [2023.04] Visual Instruction Tuning Qwen # [2025.02] Qwen2.5-VL Technical Report QwenLM/Qwen2.5-VL [2023.08] Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond Qwen-VL Deepseek # DeepSeek-VL \u6838\u5fc3\u6a21\u5757 # Encoder-Decoder # [2021.02] Learning Transferable Visual Models From Natural Language Supervision openai-clip clip-vit-base-patch16 \u4f4d\u7f6e\u7f16\u7801 # [2024.09] \u201c\u95ed\u95e8\u9020\u8f66\u201d\u4e4b\u591a\u6a21\u6001\u601d\u8def\u6d45\u8c08\uff08\u4e09\uff09\uff1a\u4f4d\u7f6e\u7f16\u7801 [2024.03] RoPE-Tie Transformer\u5347\u7ea7\u4e4b\u8def\uff1a17\u3001\u591a\u6a21\u6001\u4f4d\u7f6e\u7f16\u7801\u7684\u7b80\u5355\u601d\u8003","title":"VLM"},{"location":"5.%5B%E6%A8%A1%E5%9E%8B%5D%E5%A4%9A%E6%A8%A1%E6%80%81/VLM/#_1","text":"","title":"\u591a\u6a21\u6001\u5927\u6a21\u578b"},{"location":"5.%5B%E6%A8%A1%E5%9E%8B%5D%E5%A4%9A%E6%A8%A1%E6%80%81/VLM/#_2","text":"","title":"\u5b66\u4e60\u8d44\u6599"},{"location":"5.%5B%E6%A8%A1%E5%9E%8B%5D%E5%A4%9A%E6%A8%A1%E6%80%81/VLM/#_3","text":"[2025.04] Kimi-VL Technical Report MoonshotAI/Kimi-VL [2025.01] MiniMax-01: Scaling Foundation Models with Lightning Attention MiniMax-AI/MiniMax-01 [2024.03] VisionLLaMA: A Unified LLaMA Backbone for Vision Tasks RoPE-2D\u7684\u5f15\u5165\u6709\u52a9\u4e8e\u63d0\u5347\u6a21\u578b\u6548\u679c\u5c24\u5176\u662f\u53d8\u5206\u8fa8\u7387\u8f93\u5165\u7684\u6548\u679c Meituan-AutoML/VisionLLaMA minimind-v \u6781\u7b80vlm\u6a21\u578b LLaVA [2023.10] Improved Baselines with Visual Instruction Tuning [2023.04] Visual Instruction Tuning","title":"\u5f00\u6e90\u9879\u76ee"},{"location":"5.%5B%E6%A8%A1%E5%9E%8B%5D%E5%A4%9A%E6%A8%A1%E6%80%81/VLM/#qwen","text":"[2025.02] Qwen2.5-VL Technical Report QwenLM/Qwen2.5-VL [2023.08] Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond Qwen-VL","title":"Qwen"},{"location":"5.%5B%E6%A8%A1%E5%9E%8B%5D%E5%A4%9A%E6%A8%A1%E6%80%81/VLM/#deepseek","text":"DeepSeek-VL","title":"Deepseek"},{"location":"5.%5B%E6%A8%A1%E5%9E%8B%5D%E5%A4%9A%E6%A8%A1%E6%80%81/VLM/#_4","text":"","title":"\u6838\u5fc3\u6a21\u5757"},{"location":"5.%5B%E6%A8%A1%E5%9E%8B%5D%E5%A4%9A%E6%A8%A1%E6%80%81/VLM/#encoder-decoder","text":"[2021.02] Learning Transferable Visual Models From Natural Language Supervision openai-clip clip-vit-base-patch16","title":"Encoder-Decoder"},{"location":"5.%5B%E6%A8%A1%E5%9E%8B%5D%E5%A4%9A%E6%A8%A1%E6%80%81/VLM/#_5","text":"[2024.09] \u201c\u95ed\u95e8\u9020\u8f66\u201d\u4e4b\u591a\u6a21\u6001\u601d\u8def\u6d45\u8c08\uff08\u4e09\uff09\uff1a\u4f4d\u7f6e\u7f16\u7801 [2024.03] RoPE-Tie Transformer\u5347\u7ea7\u4e4b\u8def\uff1a17\u3001\u591a\u6a21\u6001\u4f4d\u7f6e\u7f16\u7801\u7684\u7b80\u5355\u601d\u8003","title":"\u4f4d\u7f6e\u7f16\u7801"},{"location":"6.%5B%E6%A8%A1%E5%9E%8B%5D%E8%AF%84%E6%B5%8B/Benchmark/","text":"\u5927\u6a21\u578b\u8bc4\u6d4b # \u5e38\u89c1\u8bc4\u4f30\u96c6 # chatbot-arena https://lmarena.ai/ https://huggingface.co/spaces/lmarena-ai/chatbot-arena-leaderboard \u63a8\u7406&\u77e5\u8bc6 \u4eba\u7c7b\u6700\u540e\u8003\u8bd5 https://agi.safe.ai/ \u89c6\u89c9\u63a8\u7406 https://mmmu-benchmark.github.io/ \u79d1\u5b66 https://github.com/idavidrein/gpqa \u6570\u5b66 https://artofproblemsolving.com/wiki/index.php/AIME_Problems_and_Solutions \u4ee3\u7801 \u4ee3\u7801\u751f\u6210 https://livecodebench.github.io/ \u4ee3\u7801\u7f16\u8f91 https://aider.chat/docs/leaderboards/ Agent\u7f16\u7a0b https://www.swebench.com/ \u4e8b\u5b9e https://openai.com/index/introducing-simpleqa/ https://github.com/openai/simple-evals/ \u56fe\u50cf\u7406\u89e3 https://github.com/reka-ai/reka-vibe-eval \u957f\u4e0a\u4e0b\u6587 \u591a\u8f6e\u4e00\u81f4\u6027 https://arxiv.org/html/2409.12640v2 \u591a\u8bed\u8a00 https://huggingface.co/datasets/CohereForAI/Global-MMLU open_llm_leaderboard SuperCLUE\u603b\u6392\u884c\u699c[link] Text-to-Video Generation on MSR-VTT[link] Video Generation on UCF-101[link] \u89d2\u8272\u626e\u6f14 # [2025.02] CoSER: Coordinating LLM-Based Persona Simulation of Established Roles 1.8w\u89d2\u8272\uff0c3w\u5bf9\u8bdd Neph0s/COSER [2024.08] MMRole: A Comprehensive Framework for Developing and Evaluating Multimodal Role-Playing Agents \u591a\u6a21\u6001\u89d2\u8272\u626e\u6f14\u8bc4\u4f30\uff0c85 characters, 11K images, and 14K single or multi-turn dialogues YanqiDai/MMRole [2024.01] Large Language Models are Superpositions of All Characters: Attaining Arbitrary Role-play via Self-Alignment 4k\u4e2a\u89d2\u8272\uff0c3.6w\u7684\u5bf9\u8bdd OFA-Sys/Ditto [2024.01] CharacterEval: A Chinese Benchmark for Role-Playing Conversational Agent Evaluation \u4e2d\u6587\u89d2\u8272\u626e\u6f14\u8bc4\u4f30\uff0c77\u4e2a\u89d2\u8272\uff0c1785\u4e2a\u591a\u8f6e\u5bf9\u8bdd [2023.12] RoleEval: A Bilingual Role Evaluation Benchmark for Large Language Models \u4e2d\u82f1\u53cc\u8bed\u89d2\u8272\u8bc4\u4f30\uff0c300\u4e2a\u89d2\u8272\uff0c6000\u4e2a\u95ee\u9898 [2023.10] RoleLLM: Benchmarking, Eliciting, and Enhancing Role-Playing Abilities of Large Language Models InteractiveNLP-Team/RoleLLM-public SuperCLUE-Role: \u91cd\u65b0\u5b9a\u4e49\u4e2d\u6587\u89d2\u8272\u5927\u6a21\u578b\u6d4b\u8bc4\u57fa\u51c6 \u591a\u6a21\u6001 # [2024.10] MEGA-Bench: Scaling Multimodal Evaluation to over 500 Real-World Tasks 505\u4e2a\u4efb\u52a1\uff0c8186\u4e2a\u6837\u672c\u3002 MEGA-Bench page MEGA-Bench Leaderboard","title":"Benchmark"},{"location":"6.%5B%E6%A8%A1%E5%9E%8B%5D%E8%AF%84%E6%B5%8B/Benchmark/#_1","text":"","title":"\u5927\u6a21\u578b\u8bc4\u6d4b"},{"location":"6.%5B%E6%A8%A1%E5%9E%8B%5D%E8%AF%84%E6%B5%8B/Benchmark/#_2","text":"chatbot-arena https://lmarena.ai/ https://huggingface.co/spaces/lmarena-ai/chatbot-arena-leaderboard \u63a8\u7406&\u77e5\u8bc6 \u4eba\u7c7b\u6700\u540e\u8003\u8bd5 https://agi.safe.ai/ \u89c6\u89c9\u63a8\u7406 https://mmmu-benchmark.github.io/ \u79d1\u5b66 https://github.com/idavidrein/gpqa \u6570\u5b66 https://artofproblemsolving.com/wiki/index.php/AIME_Problems_and_Solutions \u4ee3\u7801 \u4ee3\u7801\u751f\u6210 https://livecodebench.github.io/ \u4ee3\u7801\u7f16\u8f91 https://aider.chat/docs/leaderboards/ Agent\u7f16\u7a0b https://www.swebench.com/ \u4e8b\u5b9e https://openai.com/index/introducing-simpleqa/ https://github.com/openai/simple-evals/ \u56fe\u50cf\u7406\u89e3 https://github.com/reka-ai/reka-vibe-eval \u957f\u4e0a\u4e0b\u6587 \u591a\u8f6e\u4e00\u81f4\u6027 https://arxiv.org/html/2409.12640v2 \u591a\u8bed\u8a00 https://huggingface.co/datasets/CohereForAI/Global-MMLU open_llm_leaderboard SuperCLUE\u603b\u6392\u884c\u699c[link] Text-to-Video Generation on MSR-VTT[link] Video Generation on UCF-101[link]","title":"\u5e38\u89c1\u8bc4\u4f30\u96c6"},{"location":"6.%5B%E6%A8%A1%E5%9E%8B%5D%E8%AF%84%E6%B5%8B/Benchmark/#_3","text":"[2025.02] CoSER: Coordinating LLM-Based Persona Simulation of Established Roles 1.8w\u89d2\u8272\uff0c3w\u5bf9\u8bdd Neph0s/COSER [2024.08] MMRole: A Comprehensive Framework for Developing and Evaluating Multimodal Role-Playing Agents \u591a\u6a21\u6001\u89d2\u8272\u626e\u6f14\u8bc4\u4f30\uff0c85 characters, 11K images, and 14K single or multi-turn dialogues YanqiDai/MMRole [2024.01] Large Language Models are Superpositions of All Characters: Attaining Arbitrary Role-play via Self-Alignment 4k\u4e2a\u89d2\u8272\uff0c3.6w\u7684\u5bf9\u8bdd OFA-Sys/Ditto [2024.01] CharacterEval: A Chinese Benchmark for Role-Playing Conversational Agent Evaluation \u4e2d\u6587\u89d2\u8272\u626e\u6f14\u8bc4\u4f30\uff0c77\u4e2a\u89d2\u8272\uff0c1785\u4e2a\u591a\u8f6e\u5bf9\u8bdd [2023.12] RoleEval: A Bilingual Role Evaluation Benchmark for Large Language Models \u4e2d\u82f1\u53cc\u8bed\u89d2\u8272\u8bc4\u4f30\uff0c300\u4e2a\u89d2\u8272\uff0c6000\u4e2a\u95ee\u9898 [2023.10] RoleLLM: Benchmarking, Eliciting, and Enhancing Role-Playing Abilities of Large Language Models InteractiveNLP-Team/RoleLLM-public SuperCLUE-Role: \u91cd\u65b0\u5b9a\u4e49\u4e2d\u6587\u89d2\u8272\u5927\u6a21\u578b\u6d4b\u8bc4\u57fa\u51c6","title":"\u89d2\u8272\u626e\u6f14"},{"location":"6.%5B%E6%A8%A1%E5%9E%8B%5D%E8%AF%84%E6%B5%8B/Benchmark/#_4","text":"[2024.10] MEGA-Bench: Scaling Multimodal Evaluation to over 500 Real-World Tasks 505\u4e2a\u4efb\u52a1\uff0c8186\u4e2a\u6837\u672c\u3002 MEGA-Bench page MEGA-Bench Leaderboard","title":"\u591a\u6a21\u6001"},{"location":"7.%5B%E5%BA%94%E7%94%A8%5D%E4%BA%A7%E5%93%81/Agent/","text":"Agent # \u76f8\u5173\u5de5\u4f5c # [2025.03] Why Do Multi-Agent LLM Systems Fail? \u4e3a\u4ec0\u4e48\u591a Agent \u7cfb\u7edf\u603b\u662f\u5931\u8d25\uff1f [2024.10] AutoGLM: Autonomous Foundation Agents for GUIs \u4e09\u4e2ainsight\uff0c\u4e2d\u95f4\u63a5\u53e3\u8bbe\u8ba1\u3001\u81ea\u8fdb\u5316\u7684\u8bfe\u7a0bRL\u3001\u7b56\u7565\u5206\u5e03\u6f02\u79fb AutoGLM \u6f14\u793a\u89c6\u9891 [2024.03] \u6df1\u5ea6\u957f\u6587\u300f\u5434\u6069\u8fbe\uff1aAI Agent 4\u79cd\u6700\u5e38\u89c1\u7684\u8bbe\u8ba1\u6a21\u5f0f reflection\u3001tool use\u3001planning\u3001multi-agent collaboration [2024.02] Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models \u8ddfdeepresearch\u6709\u70b9\u50cf\u4e86 stanford-oval/storm [2024.01] Agent AI: Surveying the Horizons of Multimodal Interaction [\u300aAgent AI\uff1a\u591a\u6a21\u6001\u4ea4\u4e92\u524d\u6cbf\u8c03\u67e5\u300b-- \u674e\u98de\u98de\u56e2\u961f]((https://zhuanlan.zhihu.com/p/12759357195) [2023.12] An LLM Compiler for Parallel Function Calling SqueezeAILab/LLMCompiler [2023.03] Reflexion: Language Agents with Verbal Reinforcement Learning noahshinn/reflexion [2022.10] ReAct: Synergizing Reasoning and Acting in Language Models ReAct\uff0cGoogle\uff0cquery\u3001think\u3001action\u3001result\u3002 Agent\u7684\u4e5d\u79cd\u8bbe\u8ba1\u6a21\u5f0f(\u56fe\u89e3+\u4ee3\u7801) ysymyth/ReAct \u5f00\u6e90\u9879\u76ee # mem0ai/mem0 agent\u7684\u8bb0\u5fc6\u5c42 Perplexica ai\u641c\u7d22\u5f15\u64ce bytedance/deer-flow","title":"Agent"},{"location":"7.%5B%E5%BA%94%E7%94%A8%5D%E4%BA%A7%E5%93%81/Agent/#agent","text":"","title":"Agent"},{"location":"7.%5B%E5%BA%94%E7%94%A8%5D%E4%BA%A7%E5%93%81/Agent/#_1","text":"[2025.03] Why Do Multi-Agent LLM Systems Fail? \u4e3a\u4ec0\u4e48\u591a Agent \u7cfb\u7edf\u603b\u662f\u5931\u8d25\uff1f [2024.10] AutoGLM: Autonomous Foundation Agents for GUIs \u4e09\u4e2ainsight\uff0c\u4e2d\u95f4\u63a5\u53e3\u8bbe\u8ba1\u3001\u81ea\u8fdb\u5316\u7684\u8bfe\u7a0bRL\u3001\u7b56\u7565\u5206\u5e03\u6f02\u79fb AutoGLM \u6f14\u793a\u89c6\u9891 [2024.03] \u6df1\u5ea6\u957f\u6587\u300f\u5434\u6069\u8fbe\uff1aAI Agent 4\u79cd\u6700\u5e38\u89c1\u7684\u8bbe\u8ba1\u6a21\u5f0f reflection\u3001tool use\u3001planning\u3001multi-agent collaboration [2024.02] Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models \u8ddfdeepresearch\u6709\u70b9\u50cf\u4e86 stanford-oval/storm [2024.01] Agent AI: Surveying the Horizons of Multimodal Interaction [\u300aAgent AI\uff1a\u591a\u6a21\u6001\u4ea4\u4e92\u524d\u6cbf\u8c03\u67e5\u300b-- \u674e\u98de\u98de\u56e2\u961f]((https://zhuanlan.zhihu.com/p/12759357195) [2023.12] An LLM Compiler for Parallel Function Calling SqueezeAILab/LLMCompiler [2023.03] Reflexion: Language Agents with Verbal Reinforcement Learning noahshinn/reflexion [2022.10] ReAct: Synergizing Reasoning and Acting in Language Models ReAct\uff0cGoogle\uff0cquery\u3001think\u3001action\u3001result\u3002 Agent\u7684\u4e5d\u79cd\u8bbe\u8ba1\u6a21\u5f0f(\u56fe\u89e3+\u4ee3\u7801) ysymyth/ReAct","title":"\u76f8\u5173\u5de5\u4f5c"},{"location":"7.%5B%E5%BA%94%E7%94%A8%5D%E4%BA%A7%E5%93%81/Agent/#_2","text":"mem0ai/mem0 agent\u7684\u8bb0\u5fc6\u5c42 Perplexica ai\u641c\u7d22\u5f15\u64ce bytedance/deer-flow","title":"\u5f00\u6e90\u9879\u76ee"},{"location":"7.%5B%E5%BA%94%E7%94%A8%5D%E4%BA%A7%E5%93%81/Product/","text":"1. 2B # 1.1. \u5e7f\u544a # https://www.adcreative.ai/#section-pricing https://tryatria.com/ https://www.meetsocial.com/ \u8fd9\u516c\u53f8\u8981\u505a\u6295\u653e\u65b9\u5411\u7684manus\uff0c\u5148\u505acopilot\uff0c\u66ff\u4ee3\u76ee\u524d\u6295\u653e\u4f18\u5316\u5e0870%\u7684\u504f\u6267\u884c\u7684\u5de5\u4f5c\uff0c\u518d\u505a\u51b3\u7b56\u65b9\u5411\u7684\u6307\u5bfc 2. 2C # 2.1. \u5de5\u5177\u7c7b # \u5bfc\u822a toolify.ai ai\u4ea7\u54c1\u699c\u5355\uff0c\u7ade\u5bf9\u793e\u5a92\u76d1\u542c producthunt aibase.com ai-bot.cn deepresearch \u4ea7\u54c1 search.jina.ai introducing-perplexity-deep-research introducing-deep-research \u5f00\u6e90 open-deep-research togethercomputer/open_deep_research langchain-ai/open_deep_research dzhng/deep-research jina-ai/node-DeepResearch DeepSearch \u4e0e DeepResearch \u7684\u8bbe\u8ba1\u548c\u5b9e\u73b0 \u7f16\u7a0b devin \u6d77\u5916\u6536\u8d39\uff0c\u6ca1\u6709\u4f53\u9a8c lovable bolt dify webdraw codeflying \u63d0\u9700\u6c42\uff0c\u751f\u6210\u65b9\u6848\uff0c\u786e\u8ba4\u540e\u751f\u6210prd\u3001\u6d4b\u8bd5\u7528\u4f8b\u3001\u67b6\u6784\uff0c\u786e\u8ba4\u540e\u5f00\u59cb\u5199\u4ee3\u7801\u3002\u751f\u6210\u7684\u7f51\u7ad9\u8fd8\u6709\u8fd0\u8425\u540e\u53f0\uff0c\u4e0d\u8fc7\u6bd4\u8f83\u7c97\u7cd9\u3002 mgx.dev \u7ed9\u7a0b\u5e8f\u5458\u7528\uff0c\u751f\u6210\u7684\u4ee3\u7801\u53ef\u4ee5\u6539 \u79d2\u54d2 \u81ea\u7136\u8bed\u8a00\u5efa\u7ad9\uff0c\u4e0d\u66b4\u9732\u5efa\u7ad9\u8fc7\u7a0b\u3002 Claude Code \u62db\u8058 finalroundai \u4f1a\u8bae \u98de\u4e66\u4f1a\u8bae\u3002\u81ea\u52a8\u751f\u6210\u4f1a\u8bae\u7eaa\u8981\uff0c\u4f53\u9a8c\u5f88\u597d\u3002 \u5176\u4ed6 promptlayer 2.1.1. ai\u641c\u7d22 # \u77e5\u4e4e\u76f4\u7b54\uff1aAI \u641c\u7d22\u4ea7\u54c1\u4ece 0 \u5230 1 \u5b9e\u8df5\u63a2\u7d22 CoSENT\uff08\u4e00\uff09\uff1a\u6bd4Sentence-BERT\u66f4\u6709\u6548\u7684\u53e5\u5411\u91cf\u65b9\u6848 2.2. \u5a31\u4e50\u7c7b # 2.2.1. \u89d2\u8272\u626e\u6f14 # \u6d77\u5916 Chai chai_roadmap_2025 https://www.dippy.ai/ https://moescape.ai/ https://xiaoyequ9.com/ nsfw https://crushon.ai/ https://sexyai.top/#/ https://www.polybuzz.ai/ https://candy.ai/ \u56fd\u5185 https://www.zhumengdao.com/ 3. 2G #","title":"Product"},{"location":"7.%5B%E5%BA%94%E7%94%A8%5D%E4%BA%A7%E5%93%81/Product/#1_2b","text":"","title":"1. 2B"},{"location":"7.%5B%E5%BA%94%E7%94%A8%5D%E4%BA%A7%E5%93%81/Product/#11","text":"https://www.adcreative.ai/#section-pricing https://tryatria.com/ https://www.meetsocial.com/ \u8fd9\u516c\u53f8\u8981\u505a\u6295\u653e\u65b9\u5411\u7684manus\uff0c\u5148\u505acopilot\uff0c\u66ff\u4ee3\u76ee\u524d\u6295\u653e\u4f18\u5316\u5e0870%\u7684\u504f\u6267\u884c\u7684\u5de5\u4f5c\uff0c\u518d\u505a\u51b3\u7b56\u65b9\u5411\u7684\u6307\u5bfc","title":"1.1. \u5e7f\u544a"},{"location":"7.%5B%E5%BA%94%E7%94%A8%5D%E4%BA%A7%E5%93%81/Product/#2_2c","text":"","title":"2. 2C"},{"location":"7.%5B%E5%BA%94%E7%94%A8%5D%E4%BA%A7%E5%93%81/Product/#21","text":"\u5bfc\u822a toolify.ai ai\u4ea7\u54c1\u699c\u5355\uff0c\u7ade\u5bf9\u793e\u5a92\u76d1\u542c producthunt aibase.com ai-bot.cn deepresearch \u4ea7\u54c1 search.jina.ai introducing-perplexity-deep-research introducing-deep-research \u5f00\u6e90 open-deep-research togethercomputer/open_deep_research langchain-ai/open_deep_research dzhng/deep-research jina-ai/node-DeepResearch DeepSearch \u4e0e DeepResearch \u7684\u8bbe\u8ba1\u548c\u5b9e\u73b0 \u7f16\u7a0b devin \u6d77\u5916\u6536\u8d39\uff0c\u6ca1\u6709\u4f53\u9a8c lovable bolt dify webdraw codeflying \u63d0\u9700\u6c42\uff0c\u751f\u6210\u65b9\u6848\uff0c\u786e\u8ba4\u540e\u751f\u6210prd\u3001\u6d4b\u8bd5\u7528\u4f8b\u3001\u67b6\u6784\uff0c\u786e\u8ba4\u540e\u5f00\u59cb\u5199\u4ee3\u7801\u3002\u751f\u6210\u7684\u7f51\u7ad9\u8fd8\u6709\u8fd0\u8425\u540e\u53f0\uff0c\u4e0d\u8fc7\u6bd4\u8f83\u7c97\u7cd9\u3002 mgx.dev \u7ed9\u7a0b\u5e8f\u5458\u7528\uff0c\u751f\u6210\u7684\u4ee3\u7801\u53ef\u4ee5\u6539 \u79d2\u54d2 \u81ea\u7136\u8bed\u8a00\u5efa\u7ad9\uff0c\u4e0d\u66b4\u9732\u5efa\u7ad9\u8fc7\u7a0b\u3002 Claude Code \u62db\u8058 finalroundai \u4f1a\u8bae \u98de\u4e66\u4f1a\u8bae\u3002\u81ea\u52a8\u751f\u6210\u4f1a\u8bae\u7eaa\u8981\uff0c\u4f53\u9a8c\u5f88\u597d\u3002 \u5176\u4ed6 promptlayer","title":"2.1. \u5de5\u5177\u7c7b"},{"location":"7.%5B%E5%BA%94%E7%94%A8%5D%E4%BA%A7%E5%93%81/Product/#211_ai","text":"\u77e5\u4e4e\u76f4\u7b54\uff1aAI \u641c\u7d22\u4ea7\u54c1\u4ece 0 \u5230 1 \u5b9e\u8df5\u63a2\u7d22 CoSENT\uff08\u4e00\uff09\uff1a\u6bd4Sentence-BERT\u66f4\u6709\u6548\u7684\u53e5\u5411\u91cf\u65b9\u6848","title":"2.1.1. ai\u641c\u7d22"},{"location":"7.%5B%E5%BA%94%E7%94%A8%5D%E4%BA%A7%E5%93%81/Product/#22","text":"","title":"2.2. \u5a31\u4e50\u7c7b"},{"location":"7.%5B%E5%BA%94%E7%94%A8%5D%E4%BA%A7%E5%93%81/Product/#221","text":"\u6d77\u5916 Chai chai_roadmap_2025 https://www.dippy.ai/ https://moescape.ai/ https://xiaoyequ9.com/ nsfw https://crushon.ai/ https://sexyai.top/#/ https://www.polybuzz.ai/ https://candy.ai/ \u56fd\u5185 https://www.zhumengdao.com/","title":"2.2.1. \u89d2\u8272\u626e\u6f14"},{"location":"7.%5B%E5%BA%94%E7%94%A8%5D%E4%BA%A7%E5%93%81/Product/#3_2g","text":"","title":"3. 2G"},{"location":"7.%5B%E5%BA%94%E7%94%A8%5D%E4%BA%A7%E5%93%81/VibeCoding/","text":"VibeCoding # LLM + Code \u80fd\u591f\u6781\u5927\u63d0\u9ad8\u81ea\u52a8\u5316\u6c34\u5e73 \u5b66\u4e60\u8d44\u6599 # EnzeD/vibe-coding vibe coding\u7684\u6559\u7a0b\u3002\u5173\u952e\u539f\u5219\uff1aPlanning is everything\u3002","title":"VibeCoding"},{"location":"7.%5B%E5%BA%94%E7%94%A8%5D%E4%BA%A7%E5%93%81/VibeCoding/#vibecoding","text":"LLM + Code \u80fd\u591f\u6781\u5927\u63d0\u9ad8\u81ea\u52a8\u5316\u6c34\u5e73","title":"VibeCoding"},{"location":"7.%5B%E5%BA%94%E7%94%A8%5D%E4%BA%A7%E5%93%81/VibeCoding/#_1","text":"EnzeD/vibe-coding vibe coding\u7684\u6559\u7a0b\u3002\u5173\u952e\u539f\u5219\uff1aPlanning is everything\u3002","title":"\u5b66\u4e60\u8d44\u6599"}]}